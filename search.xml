<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>计算机网络自顶向下方法</title>
      <link href="/2024/05/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E6%96%B9%E6%B3%95/"/>
      <url>/2024/05/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="计算机网络-自顶向下方法"><a href="#计算机网络-自顶向下方法" class="headerlink" title="计算机网络 自顶向下方法"></a>计算机网络 自顶向下方法</h1><hr><h2 id="计算机网络与互联网"><a href="#计算机网络与互联网" class="headerlink" title="计算机网络与互联网"></a><strong>计算机网络与互联网</strong></h2><p>由节点和边构成的网络我们称其为计算机网络</p><p>从服务的角度看，计算机网络是分布式的应用进程和为分布式应用进程提供服务的基础设施。</p><h2 id="一些术语："><a href="#一些术语：" class="headerlink" title="一些术语："></a>一些术语：</h2><h3 id="节点"><a href="#节点" class="headerlink" title="节点"></a>节点</h3><h4 id="主机节点"><a href="#主机节点" class="headerlink" title="主机节点"></a>主机节点</h4><p>各种联网的设备，主机 服务器、包括联网的机顶盒，冰箱上运行的应用程序</p><p>主机节点和主机上运行的应用程序也被成为网络边缘</p><h4 id="数据交换节点："><a href="#数据交换节点：" class="headerlink" title="数据交换节点："></a>数据交换节点：</h4><p>交换机、路由器等网络交换设备</p><p>互联的路由器交换机也被成为网络核心</p><h3 id="边"><a href="#边" class="headerlink" title="边"></a>边</h3><p>通信链路</p><p>光纤、同轴电缆、无线电、卫星</p><p>传输速率 就是带宽bps （bit per second）单位是bit 而不是Byte 所以所谓的百兆带宽也就10M多的下载速度&#x3D;     &#x3D;</p><h4 id="接入网链路"><a href="#接入网链路" class="headerlink" title="接入网链路"></a>接入网链路</h4><p>主机连接到互联网的链路</p><h4 id="主干链路"><a href="#主干链路" class="headerlink" title="主干链路"></a>主干链路</h4><p>路由器之间的链路</p><h3 id="协议"><a href="#协议" class="headerlink" title="协议"></a>协议</h3><p>协议是支撑互联网工作的标准，在通信过程中所要遵守的规则</p><p>协议定义了两个或多个通信实体之间交换的报文格式和次序，以及在报文传输或接收或其他事件方面所采取的动作</p><h3 id="Internet"><a href="#Internet" class="headerlink" title="Internet"></a>Internet</h3><p>Internet是网络的网络，是多个局域网相连得到的大的网络结构</p><h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p>网络分为了三个结构</p><p>边缘系统，核心系统和接入系统</p><p>边缘系统就是上面提到的主机节点以及主机节点上运行的程序 比如Web</p><p>核心系统就是上面的数据链路以及路由器以及交换机</p><p>接入系统把边缘系统接入到核心系统中从而达到互联的效果,</p><p>比如WIfi 再比如接入到家的光纤，卫星 等等 都算作接入网</p><h3 id="客户服务器模式"><a href="#客户服务器模式" class="headerlink" title="客户服务器模式"></a>客户服务器模式</h3><p>客户端向服务端发送请求接受服务</p><p>比如说浏览器—服务器    客户端—服务器</p><h3 id="对等（peer-peer）模式"><a href="#对等（peer-peer）模式" class="headerlink" title="对等（peer-peer）模式"></a>对等（peer-peer）模式</h3><p>很少甚至没有专门的服务器 在这个模式下 主机既可以是客户端又可以是服务器 我们可以向别人请求数据，别人也可以向我们请求数据（磁力链接&#x3D;  &#x3D;）</p><h3 id="采用网络设施的面向连接服务"><a href="#采用网络设施的面向连接服务" class="headerlink" title="采用网络设施的面向连接服务"></a>采用网络设施的面向连接服务</h3><p>在端与系统之间传输数据</p><h3 id="握手"><a href="#握手" class="headerlink" title="握手"></a>握手</h3><p>在传输数据之前做好准备，两个通信主机之间为连接建立状态</p><h3 id="TCP-传输控制协议（Transmission-Control-Protocol）"><a href="#TCP-传输控制协议（Transmission-Control-Protocol）" class="headerlink" title="TCP-传输控制协议（Transmission Control Protocol）"></a>TCP-传输控制协议（Transmission Control Protocol）</h3><p>是Internet上面向连接的服务</p><p>可以可靠的按顺序返回数据对数据做确认如果丢包会重新传输</p><h4 id="流量控制"><a href="#流量控制" class="headerlink" title="流量控制"></a>流量控制</h4><p>保证数据不会淹没对方</p><h4 id="拥塞控制"><a href="#拥塞控制" class="headerlink" title="拥塞控制"></a>拥塞控制</h4><p>当网络拥塞时，发送方降低传送速率</p><p>+++</p><h2 id="笔记："><a href="#笔记：" class="headerlink" title="笔记："></a>笔记：</h2><h3 id="网络核心："><a href="#网络核心：" class="headerlink" title="网络核心："></a>网络核心：</h3><p>网络资源（比如带宽）被分成片供个人使用，有按频率分片（Frequency-division-multiplexing），按时间分片(Time-division-multiplexing)，按波长分片(Wave-division-multiplexing)</p><p>网络核心的关键功能就是转发和路由</p><p>转发 就是将分组从路由器的输入链路转移到输出链路</p><p>路由 决定分组采用的源到目标的路径</p><h4 id="电路交换"><a href="#电路交换" class="headerlink" title="电路交换"></a><strong>电路交换</strong></h4><p>电路交换是在两个端到端之间分配出一条专用的网络供通信使用</p><p>端到端之间的资源被分配给从源端到目标端的呼叫叫做<strong>Call</strong></p><p>电路交换的好处是独享资源，每个呼叫建立起来就能够保证性能，不同于分组交换可能会受到网络拥堵造成的延迟和丢包。</p><p>如果建立通讯而没有使用就会造成资源的浪费</p><p>通常被传统电话网络使用而不用于计算机当中，因为建立连接时间长，计算机之间的通信具有突发性，如果使用线路交换，浪费的片比较多（即便这个片没有数据传递，其所占据的片也不能被别的呼叫使用）</p><h4 id="分组交换"><a href="#分组交换" class="headerlink" title="分组交换"></a><strong>分组交换</strong></h4><p>不同于电路交换，分组交换不再分为一个个的专用通道，而是使用全部的信道来通信</p><p>主机和主机之间的通讯被分为一个个的单位，而这个的单位我们称其为分组（packet）在每个交换节点间通过存储-转发的方式来进行传输</p><p>为什么要使用存储-转发的方式进行传输呢？ 因为如果你拿到一个bit就向其他交换机传输这一比特的话，就会同时占用两条信道，信道也就没有了共享的效果，变成了一个专用信道。</p><p>分组交换适合应对突发式的数据传输，因为其资源共享且简单不必建立呼叫，但是过度使用可能会造成<strong>网络拥塞</strong>（分组延时和丢包）对可靠的传输数据需要协议来约束。也就是<strong>拥塞控制</strong>。</p><h5 id="排队延迟"><a href="#排队延迟" class="headerlink" title="排队延迟"></a>排队延迟</h5><p>每台分组交换机都有多条链路相连，对于每条线路，都有一个输出缓存（也叫输出队列）</p><p>如果到达速率&gt;链路的传输速率，分组就会排队，等待输出</p><p>如果路由器的缓存用完了，分组就会抛弃，也就是丢包</p><h4 id="数据报的工作原理"><a href="#数据报的工作原理" class="headerlink" title="数据报的工作原理"></a>数据报的工作原理</h4><p>在通信前，无需建立连接，有数据就传输，每个分组都独立路由（路径不同，可能会失序），路由器根据分组的目标地址进行路由，</p><h3 id="接入网与物理媒体"><a href="#接入网与物理媒体" class="headerlink" title="接入网与物理媒体"></a>接入网与物理媒体</h3><h3 id="住宅接入-Modem"><a href="#住宅接入-Modem" class="headerlink" title="住宅接入 Modem"></a>住宅接入 Modem</h3><p>将上网数据调制加载到音频信号上，在电话线上传输，在局域将其中的数据解调出来，反之亦然</p><p>在互联网早期，由于专线接入家庭，成本高且收益差，所以使用电话线来做传输 有保证的带宽只有4KHz，在家里接入一个猫（光猫）也就是拨号调制解调器，这样就可以上网冲浪了（为什么叫冲浪呢，因为在音频的信号上 起起伏伏就和冲浪一样）</p><h5 id="拨号调制解调器"><a href="#拨号调制解调器" class="headerlink" title="拨号调制解调器"></a>拨号调制解调器</h5><p>56kbps的速率接入路由器，不能同时上网打电话，更不能总是在线</p><p>采用现有的电话线，但是根据频率，划分出用于音通信的部分，和上行带宽和下行带宽</p><h4 id="线缆网络"><a href="#线缆网络" class="headerlink" title="线缆网络"></a>线缆网络</h4><p>有线电视信号线缆双向改造，FDM在不同频段传输不同信道的数据，数字电视和上网数据（上下行）</p><p>铜芯线缆和光纤网络将各个家庭用户接入到ISP路由器，各个用户共享到线缆头端的接入网络</p><h4 id="企业接入网络"><a href="#企业接入网络" class="headerlink" title="企业接入网络"></a>企业接入网络</h4><p>被企业和大学采用，端系统直接接到以太网交换机上</p><h4 id="无线接入网络"><a href="#无线接入网络" class="headerlink" title="无线接入网络"></a>无线接入网络</h4><p>各无线端系统共享无线接入网络（端系统到无线路由器）</p><p>通过基站或者接入点</p><h5 id="无线LANs"><a href="#无线LANs" class="headerlink" title="无线LANs"></a>无线LANs</h5><p>靠路由器来接入互联网 在建筑物内部，11，54Mbps的传输速率</p><h5 id="广域无线接入"><a href="#广域无线接入" class="headerlink" title="广域无线接入"></a>广域无线接入</h5><p>由运营商提供1~10Mbps</p><p>3G，4G，LTE</p><h4 id="物理媒体"><a href="#物理媒体" class="headerlink" title="物理媒体"></a>物理媒体</h4><p>把互联网连接起来的介质</p><p>引导型媒体： 信号沿着固体媒介被导引比如同轴电缆、光纤、双绞线</p><h4 id="非引导媒体："><a href="#非引导媒体：" class="headerlink" title="非引导媒体："></a>非引导媒体：</h4><p>信号自由从传播：无线电</p><h5 id="双绞线"><a href="#双绞线" class="headerlink" title="双绞线"></a>双绞线</h5><p>两根绝缘铜线</p><h5 id="同轴电缆"><a href="#同轴电缆" class="headerlink" title="同轴电缆"></a>同轴电缆</h5><p>两根同心的铜导线 双向，有基带电缆和宽带电缆电缆上有多个信道</p><h5 id="光缆"><a href="#光缆" class="headerlink" title="光缆"></a>光缆</h5><p>光脉冲，每个脉冲表示一个bit，在玻璃纤维中传输</p><p>点到点高速传输 10Gbps~100Gbps传输速率</p><p>在两个中继器之间可以有很长距离，不受电磁噪声的干扰</p><h4 id="无线链路"><a href="#无线链路" class="headerlink" title="无线链路"></a>无线链路</h4><p>开放空间传输电磁波，携带需要传输的数据，无需线缆  LAN（WIFI）蜂窝 卫星</p><h4 id="Internet结构和ISP"><a href="#Internet结构和ISP" class="headerlink" title="Internet结构和ISP"></a>Internet结构和ISP</h4><p>在网络的最中心，一些为数不多的充分连接的大范围网络</p><p>ISP即网络服务提供商 比如中国联通、电信</p><p>第一层ISP 国家&#x2F;国际覆盖，速率极高，与大量的第二层ISP和其他客户网络相连</p><p>第二层ISP 区域性的ISP</p><p>POP高层ISP面对客户的接入点，设计费用结算</p><p>IXP 多个ISP对等互联互通的地方</p><p>很多内容提供商ICP比如Google Akamai会部署自己的网络，连接自己的数据中心，并且连接很多Local ISP和各级ISP 靠近自己用户</p><h3 id="分组交换-延时-吞吐量"><a href="#分组交换-延时-吞吐量" class="headerlink" title="分组交换 延时 吞吐量"></a>分组交换 延时 吞吐量</h3><h4 id="丢失和延迟产生的原因："><a href="#丢失和延迟产生的原因：" class="headerlink" title="丢失和延迟产生的原因："></a>丢失和延迟产生的原因：</h4><p>分组到达链路的速率超过了链路的输出的能力，就会丢失</p><h5 id="处理时延"><a href="#处理时延" class="headerlink" title="处理时延"></a>处理时延</h5><p>检查分组的首部和决定该分组导向何处需要的时间是处理时延的一部分，此外，包括检查比特级别的差错所需要的时间也是处理时延。</p><h5 id="排队时延"><a href="#排队时延" class="headerlink" title="排队时延"></a>排队时延</h5><p>在输出链路上等待的时间</p><p>排队延迟的长度取决于其路由器上的拥塞程度（前面排了多少分组）</p><p>流量强度 &#x3D; $\frac{分组长度*分组到达队列平均速率}{链路带宽}$</p><h5 id="传输延时"><a href="#传输延时" class="headerlink" title="传输延时"></a>传输延时</h5><p>R &#x3D; 链路带宽</p><p>L &#x3D; 分组长度</p><p>传输延时 &#x3D;  $\frac{L}{R}$</p><p>将分组转发到链路上的延时，也就是储存转发的延时。</p><h5 id="传播延时"><a href="#传播延时" class="headerlink" title="传播延时"></a>传播延时</h5><p>在物理链路上的传输时间（比如光纤，同轴双绞线之类的）</p><p>同样的 传播延时 &#x3D; $\frac{物理链路长度}{媒介上的传播速度}$</p><h5 id="Internet的延时和路由"><a href="#Internet的延时和路由" class="headerlink" title="Internet的延时和路由"></a>Internet的延时和路由</h5><p>沿着路径向每个路由器发送探测分组</p><p>路由器向发送方返回分组</p><p>发送方和回复之间间隔计时</p><h5 id="吞吐量"><a href="#吞吐量" class="headerlink" title="吞吐量"></a>吞吐量</h5><p>在源端和目标端的速率（$\frac{数据量}{单位时间}$）</p><p>瞬间吞吐量 在一个时间点的速率</p><p>平均吞吐量 长时间的平均值</p><h3 id="协议层次和服务模型"><a href="#协议层次和服务模型" class="headerlink" title="协议层次和服务模型"></a>协议层次和服务模型</h3><h4 id="服务"><a href="#服务" class="headerlink" title="服务"></a>服务</h4><p>底层实体向上层提供他们之间通信的能力</p><p>服务用户</p><p>服务提供者</p><h4 id="原语"><a href="#原语" class="headerlink" title="原语"></a>原语</h4><p>上层使用下层服务的形式，高层使用低层提供的服务，以及低层向高层提供服务都是通过服务访问原语来进行交互的形式</p><p>说白了就是底层给的函数接口</p><h4 id="服务访问点"><a href="#服务访问点" class="headerlink" title="服务访问点"></a>服务访问点</h4><p>上层用下层提供服务通过层间接口的地点</p><p>比如邮箱</p><p>地址</p><p>端口</p><h4 id="服务的类型"><a href="#服务的类型" class="headerlink" title="服务的类型"></a>服务的类型</h4><h5 id="面向无连接的服务"><a href="#面向无连接的服务" class="headerlink" title="面向无连接的服务"></a>面向无连接的服务</h5><p>两个对等层实体在通信前不需要建立一个连接，不预留资源，不需要双方活跃</p><p>不可靠，可能重复，可能失序</p><p>IP分组 数据包</p><p>适合传送零星数据</p><h5 id="面向连接的服务"><a href="#面向连接的服务" class="headerlink" title="面向连接的服务"></a>面向连接的服务</h5><p>过程：</p><p>建立连接 通信 拆除连接</p><p>用于大数据块的传输</p><p>保序</p><h4 id="服务和协议的区别"><a href="#服务和协议的区别" class="headerlink" title="服务和协议的区别"></a>服务和协议的区别</h4><p>服务是底层向上层提供他们之间的通信 通过原语来操作</p><p>协议是对等实体之间相互通信需要遵守的规则</p><p>本层协议的实现选哟下层提供的服务来实现</p><p>本层实体通过的协议为上层提供更高级的服务</p><h4 id="分层实现的好处："><a href="#分层实现的好处：" class="headerlink" title="分层实现的好处："></a>分层实现的好处：</h4><p>概念化结构清晰</p><p>结构化 模块维护升级方便</p><h4 id="Internet协议栈"><a href="#Internet协议栈" class="headerlink" title="Internet协议栈"></a>Internet协议栈</h4><h5 id="应用层-网络应用"><a href="#应用层-网络应用" class="headerlink" title="应用层 网络应用"></a>应用层 网络应用</h5><p>为人类用户或者其他应用进程提供网络应用服务</p><p>FTP HTTP SMTP DNS</p><h5 id="传输层-主机之间数据传输"><a href="#传输层-主机之间数据传输" class="headerlink" title="传输层 主机之间数据传输"></a>传输层 主机之间数据传输</h5><p>在网络层提供的端到端基础上细分为进程到进程 把不可靠通信变为可靠通信</p><p>TCP UDP</p><h5 id="网络层-为数据报从源到目标选择路由"><a href="#网络层-为数据报从源到目标选择路由" class="headerlink" title="网络层 为数据报从源到目标选择路由"></a>网络层 为数据报从源到目标选择路由</h5><p>主机和主机之间的通信，端到端通信 不可靠</p><p>IP 路由协议</p><h5 id="链路层-相邻节点之间数据传输"><a href="#链路层-相邻节点之间数据传输" class="headerlink" title="链路层 相邻节点之间数据传输"></a>链路层 相邻节点之间数据传输</h5><p>相邻两个网络节点之间的数据传输</p><p>可靠或不可靠</p><h5 id="物理层-线路上传输bit"><a href="#物理层-线路上传输bit" class="headerlink" title="物理层 线路上传输bit"></a>物理层 线路上传输bit</h5><p>物理层的任务是将该帧的一个个比特从一 个节点移动到下一个节点</p><p> 接受端把物理信号转换为0 1</p><p>OSI模型</p><p>OSI模型在应用层和传输层之间加入了表示层和和会话层</p><h4 id="表示层"><a href="#表示层" class="headerlink" title="表示层"></a>表示层</h4><p>允许应用解释传输的数据 加密 压缩 机器相关的表示转换</p><h4 id="会话层"><a href="#会话层" class="headerlink" title="会话层"></a>会话层</h4><p>数据交换的同步 检查点 恢复</p><p>这两层在Internet协议里是 归应用层自己去做的</p><h4 id="封装与解封装"><a href="#封装与解封装" class="headerlink" title="封装与解封装"></a>封装与解封装</h4><p>在源端会做一个大的封装 每一层都把自己的头加在 传输数据里</p><p>各层次协议数据单元</p><p>应用层：报文 message</p><p>传输层 报文段 segment TCP段 UDP数据报</p><p>网络层 分组 packet</p><p>数据链路层 帧 frame</p><p>物理层 位 bit</p><h2 id="应用层"><a href="#应用层" class="headerlink" title="应用层"></a><strong>应用层</strong></h2><h4 id="网络应用体系结构"><a href="#网络应用体系结构" class="headerlink" title="网络应用体系结构"></a>网络应用体系结构</h4><h5 id="客户服务器模式-client-server"><a href="#客户服务器模式-client-server" class="headerlink" title="客户服务器模式 client server"></a>客户服务器模式 client server</h5><p>服务器 一直运行</p><p>有固定的IP地址和周知的端口号</p><p>扩展性差</p><p>客户端主动和服务器通信 </p><p>与互联网间歇性连接</p><h5 id="对等模式-p2p"><a href="#对等模式-p2p" class="headerlink" title="对等模式 p2p"></a>对等模式 p2p</h5><p>没有一个一直运行的服务 </p><p>任意端系统之间可以通信 每个节点技是客户端又是服务器</p><p>参与连接的主机可以间歇性改变IP地址</p><p>比如迅雷</p><h3 id="进程通信"><a href="#进程通信" class="headerlink" title="进程通信"></a>进程通信</h3><h4 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h4><p>在主机上运行的应用程序</p><p>在同一个主机可以用进程间通信机制通信</p><p>不同主机可以通过交换报文来通信</p><p> 进程为了接受报文 必须有一个标识 SAP</p><h5 id="主机-唯一的32位地址"><a href="#主机-唯一的32位地址" class="headerlink" title="主机 唯一的32位地址"></a>主机 唯一的32位地址</h5><p>但是仅仅有Ip地址不能唯一的表示意给进程 因为一台设备上同时会有多个进程在运行</p><p>使用TCP 或者UDP进行传输</p><p>HTTP TCP 80 端口 默认web页面 TCP 25  ftp TCP 2</p><p>一个进程用 IP+port表示端节点</p><p>层间接口所需要的信息</p><p>要传输的报文</p><p>对方的应用标识（谁来传的）</p><p>对望应用进程标识（传给谁）</p><p><strong>报文段</strong></p><p>源端口号目标端口号 </p><p>将IP地址向下交给IP实体 用于封装IP数据段 源IP以及目标IP</p><p><strong>socket是本地IP 本地端口和对方 IP 对方端口的一个标识</strong></p><p><strong>TCP socket 是一个会话关系</strong></p><p>如果Socket 每次传输报文都携带这么多信息 太繁琐 不方便管理</p><p>所以使用代号标示通信的双方或单方 socket</p><p>Tcp socket</p><table><thead><tr><th>源IP</th><th>源端口</th><th>目标IP目标</th><th>端口</th></tr></thead><tbody><tr><td></td><td></td><td></td><td></td></tr></tbody></table><p>两个进程之间的通信需要之前建立连接 两个进程的通信会持续一段时间</p><p>可以用一个整数  表示 两个应用实体之间的通信关系</p><p>就像你经常寄东西 直接给你个标识码 就不用每次都填那么多东西了</p><p>穿过层间接口的信息量最小</p><p>源IP 源端口  目标IP 目标端口</p><p>UDP socket 没有目标IP和端口</p><p>因此每次传输数据的时候需要指定对方IP和端口</p><p>好处是 不用握手 少了建立连接的延时</p><h3 id="应用层协议"><a href="#应用层协议" class="headerlink" title="应用层协议"></a>应用层协议</h3><p>运行在不同端系统上的应用进程如何互相交换报文</p><ul><li>交换的报文类型，请求和应答报文</li><li>各种报文类型的语法，报文的各个字段的描述</li><li>字段的语义</li><li>进程何时发送报文 对报文进行相应</li></ul><p>公开协议：</p><ul><li>允许互操作 </li><li>RFC文档定义</li><li>HTTP SMTP</li></ul><p>web应用 HTTP协议 Web客户端 HTML</p><h4 id="应用层对传输层提供服务的指标"><a href="#应用层对传输层提供服务的指标" class="headerlink" title="应用层对传输层提供服务的指标"></a>应用层对传输层提供服务的指标</h4><p>数据丢失率</p><ul><li>有些应用需要100%可靠传输（文件）</li><li>有些应用在一定比例的丢失无所谓（直播）</li></ul><p>延迟</p><ul><li>一些应用出于有效性考虑对时间有限制</li><li>打游戏 电话 上网冲浪</li></ul><p>吞吐</p><p>安全性</p><ul><li>机密</li><li>完整</li><li>可认证</li></ul><p>安全TCP</p><ul><li>TCP &amp; UDP</li><li>都没有加密</li><li>明文通过互联网传输，甚至密码</li></ul><p>SSL</p><ul><li>在TCP上面实现，提供加密的TCP连接</li><li>私密性</li><li>数据完整性</li><li>端到端的鉴别</li></ul><p>SSL在应用层</p><ul><li>应用采用SSL库，SSL库使用TCP通信</li></ul><p>SSL socket API</p><ul><li>应用通过API将明文交给socket，SSL将其加密在互联网上传输</li></ul><hr><h3 id="Web-and-Http"><a href="#Web-and-Http" class="headerlink" title="Web and Http"></a>Web and Http</h3><h4 id="HTTP概况"><a href="#HTTP概况" class="headerlink" title="HTTP概况"></a>HTTP概况</h4><p>HTTP即Hypertext Transfer Protocol 超文本传输协议</p><p>使用TCP</p><ul><li>客户发起一个与服务器的TCP连接 端口号为80</li><li>服务器接受客户的TCP连接</li><li>在浏览器与Web服务器交换HTTP报文</li><li>TCP连接关闭</li></ul><p>HTTP是无状态的</p><p>服务器并不维护关于客户的任何信息</p><p>非持久HTTP</p><ul><li>最多只有一个对象在TCP连接上发送</li><li>下载多个对象需要多个TCP链接</li><li>HTTP&#x2F;1.0使用非持久连接</li></ul><p>持久HTTP</p><p>多个对象可以在一个TCP链接上传输</p><p>HTTP&#x2F;1.1 默认使用持久HTTP </p><h4 id="响应时间模型"><a href="#响应时间模型" class="headerlink" title="响应时间模型"></a>响应时间模型</h4><p>往返时间 RTT</p><p>一个小的分组从客户端到服务器，再回到客户端的时间</p><p>响应时间</p><ul><li>一个RTT用来发起TCP连接</li><li>一个RTT用来HTTP请求 等待HTTP响应</li><li>文件传输时间</li></ul><p>$$<br>2RTT + 传输时间<br>$$</p><h4 id="持久HTTP"><a href="#持久HTTP" class="headerlink" title="持久HTTP"></a>持久HTTP</h4><p>非持久HTTP的缺点</p><ul><li><p>每个对象都需要两个RTT</p></li><li><p>操作系统必须为每个TCP连接分配资源</p></li><li><p>浏览器通常打开并行TCP连接，以获取引用对象</p></li></ul><p>持久HTTP</p><ul><li>服务器发送响应后仍保持TCP连接</li><li>在相同客户端和服务器之间的后续请求和响应报文通过相同的连接进行传送</li><li>客户端在遇到一个引用对象的时候，就可以尽快发送该对象的请求</li></ul><p>非流水方式的持久HTTP</p><ul><li><p>客户端在收到前一个响应后发送新请求</p></li><li><p>每个引用花费一个RTT</p></li></ul><p>流水方式的持久HTTP（并行处理）</p><ul><li>HTTP&#x2F;1.1的默认模式</li><li>客户端遇到一个引用对象就产生一个请求</li><li>所有引用的对象只花费一个RTT是可能的</li></ul><h4 id="HTTP请求报文"><a href="#HTTP请求报文" class="headerlink" title="HTTP请求报文"></a>HTTP请求报文</h4><p>HTTP有请求和响应两种格式的报文</p><p><img src="https://github.com/sizhouLiu/sizhouLiu.github.io/blob/master/2024/05/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E6%96%B9%E6%B3%95/image-20240125221710700.png?raw=true" alt="image-20240125221710700"></p><img src="/2024/05/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E6%96%B9%E6%B3%95/05/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E6%96%B9%E6%B3%95/image-20240125221710700.png" class title="This is an example image"><h5 id="提交表单输入"><a href="#提交表单输入" class="headerlink" title="提交表单输入"></a>提交表单输入</h5><p>POST</p><ul><li>网页通常包括表单输入</li><li>包含在实体主体中的输入被提交到服务器</li></ul><p>URL方式</p><p>GET</p><p>通过请求行的URL进行上载 （就是?xxx&#x3D;那玩意）</p><p>HTTP&#x2F;1.1</p><p>PUT</p><p>将实体主题的文件上载到URL规定的路径</p><p>DELETE</p><p>删除URL规定的文件</p><p>其实这俩都可以用POST替代</p><h4 id="HTTP响应报文"><a href="#HTTP响应报文" class="headerlink" title="HTTP响应报文"></a>HTTP响应报文</h4><p><img src="https://github.com/sizhouLiu/sizhouLiu.github.io/blob/master/2024/05/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E6%96%B9%E6%B3%95/image-20240125222950794.png?raw=true" alt="img"></p><h4 id="Cookies"><a href="#Cookies" class="headerlink" title="Cookies"></a>Cookies</h4><p>大多数主要的门户网站都使用cookies</p><ol><li>在HTTP报文中有一个cookies的首部行</li><li>在HTTP请求报文含有一个cookies的首部行</li><li>在用户端系统中保留有一个cookies文件 由用户的浏览器管理</li><li>在Web站点由一个后端数据库</li></ol><h4 id="Web缓存"><a href="#Web缓存" class="headerlink" title="Web缓存"></a>Web缓存</h4><ul><li>缓存既是客户端又是服务器</li><li>缓存一般由ISP安装</li></ul><p>使用Web缓存的好处</p><ul><li>降低客户端的请求响应时间</li><li>减少内部接入Internet接入链路的流量</li><li>采用缓存后较弱的ICP也能有效提供内容</li></ul><p>条件GET方法</p><ul><li>如果缓冲器中的对象拷贝是最新的，就不要发送对象</li><li>缓冲器 在HTTP请求中指定缓存拷贝日期</li><li>服务器 如果缓存拷贝陈旧，则响应报文没包含对象</li></ul><h3 id="FTP"><a href="#FTP" class="headerlink" title="FTP"></a>FTP</h3><p>文件传输协议</p><p>向远程主机上传输文件或接受文件</p><p>端口号为21</p><p>FTP客户端与服务器通过21号端口联系 并使用TCP为传输协议</p><p>客户端通过控制连接获得身份确认（账号密码）这玩意比较古老都是明文传输</p><p>客户端通过控制连接发送命令浏览远程目录</p><p>收到传输命令时 服务器打开一个到客户端的数据连接</p><p>一个文件传输完成后服务器关闭连接</p><p>服务器打开第二个TCP数据连接用来传输另一个文件</p><p>FTP服务器维护用户的状态信息，当前路径 用户账户与控制连接对应</p><h3 id="Email"><a href="#Email" class="headerlink" title="Email"></a>Email</h3><p>三个主要组成部分</p><ul><li>用户代理</li><li>邮件服务器</li><li>简单邮件传输协议</li></ul><p>用户代理</p><ul><li>撰写编辑阅读邮件</li><li>比如Outlook</li><li>输出和输入邮件保存在服务器上</li></ul><p>邮件服务器</p><ul><li>邮箱中管理和维护发给用户的邮件</li><li>输出报文队列保存待发送邮件</li><li>邮件服务器之间的SMTP协议发送email报文<ul><li>客户发送邮件</li><li>接受端邮件服务器</li></ul></li></ul><h4 id="SMTP"><a href="#SMTP" class="headerlink" title="SMTP"></a>SMTP</h4><p>交换email报文的协议</p><ul><li>使用TCP在客户端和服务器之间传送报文</li><li>端口号为25</li><li>直接传输从发送方到接收方服务器</li><li>三个阶段<ul><li>握手</li><li>传输报文</li><li>关闭</li></ul></li><li>命令 响应<ul><li>命令 ASCII文本</li><li>响应 状态码和状态信息</li></ul></li><li>报文必须为7为ASCII码</li></ul><p>邮件服务器有一个队列 会攒一波 定期去发送</p><p>SMTP使用持久连接</p><p>SMTP 要求报文为7位ASCLII编码</p><p>SMTP服务器使用 CRLF CRLF决定报文的尾部</p><p>HTTP 拉 pull</p><p>SMTP 推 push</p><p>两者都是ASCII形式的命令 响应交互</p><p>HTTP 每个镀锡那个封装在各自的响应报文中</p><p>SMTP 多个对象包含在一个报文中</p><h4 id="邮件报文格式"><a href="#邮件报文格式" class="headerlink" title="邮件报文格式"></a>邮件报文格式</h4><p>首部行 to</p><p>From</p><p>Subject</p><p>主体 报文只能是ASCII字符</p><h5 id="多媒体扩展："><a href="#多媒体扩展：" class="headerlink" title="多媒体扩展："></a>多媒体扩展：</h5><p>MIME 多媒体邮件扩展</p><p>在报文首部用额外行申明MIME的内容类型</p><p>使用BASE64编码</p><p>Base64 是一种把不在ASCII中的编码改写成ASCII编码的一种格式</p><p>SMTP传送到接受方的邮件服务器</p><p>邮件访问协议 从服务器访问邮件</p><p>​POP邮局访问协议</p><p>用户身份确认 代理服务器并下载</p><p>HTTP：</p><p>方便</p><h3 id="DNS"><a href="#DNS" class="headerlink" title="DNS"></a>DNS</h3><p>IP地址标识主机 路由器 </p><p>但是IP地址不好记忆 不便于人类使用</p><p>人类用户提供要访问机器的字符串名称</p><p>由DNS负责转换成为二进制的网络地址</p><p>DNS需要解决的问题：</p><ul><li><p>如何命名设备</p><ul><li><p>用有意义的字符串 好记 便于人类使用</p></li><li><p>剞劂一个平面命名的重名问题 层次化命名</p></li></ul></li><li><p>如何完成名字到IP地址的转换</p><ul><li>分布式的数据库维护和响应名字查询</li></ul></li></ul><p>DNS的总体思路</p><ul><li>分层的基于域的命名机制</li><li>若干分布式数据完成名字到IP地址的转换</li><li>运行在UDP之上端口号为53的应用服务</li><li>和兴Internet功能 但以应用层协议实现</li></ul><p>DNS主要目的</p><ul><li>实现主机名IP地址的转换</li><li>其他目的</li><li>邮件服务器别名到邮件服务器正规名字的转换</li><li>负载均衡</li></ul><p>DNS域名结构</p><p>一个层面的命名设备会有很多重名</p><p>DNS采用层次树状结构的命名方法</p><p>Internet根被分为几百个顶级域</p><p>通用的  .com .edu  .int .net .orrg</p><p>国家的  .cn .us .jp</p><p>每个子域下面可花费为若干个子域 </p><p>树叶是主机</p><h4 id="DNS名字空间"><a href="#DNS名字空间" class="headerlink" title="DNS名字空间"></a>DNS名字空间</h4><p>域名 从本域往上 直到树根</p><p>中间使用“.”间隔不同级别</p><p>例如 ustc.edu.cn</p><p>域的域名可标识一个域</p><p>主机的域名 一个域上的一个主机</p><h4 id="域名的管理"><a href="#域名的管理" class="headerlink" title="域名的管理"></a>域名的管理</h4><p>一个域管理其下的子域</p><p>.jp被划分为 ac.jp co.jp</p><p>.cn 被划分为edu.cn com.cn</p><p>域与物理网络无关</p><p>域遵从组织界限而不是物理网络</p><ul><li><p>一个域的主机可以不在一个网络</p></li><li><p>一个网路哦哦对主机不一定在一个域</p></li></ul><p>域的划分是逻辑的，而不是物理的</p><p>区域</p><ul><li><p>区域的花费由区域管理者自己决定</p></li><li><p>将DNS名字空间划分为互不相交的区域你没u给区域都是树的一部分</p></li></ul><p>名字服务器</p><ul><li>每个区域都有一个名字服务器 维护着他所管辖区域的权威信息</li><li>名字服务允许放置在区域之外 以保证可靠性</li></ul><p>TLD服务器 </p><ul><li>顶级域服务器负责顶级域名 比如.com .org .net 和所有国家的域.cn .uk </li><li>Network solutions 公司维护com TLD服务器</li><li>Educause 公司维护edu TLD 服务器</li></ul><p>本地名字服务器</p><ul><li>并不严格属于层次结构</li><li>每个ISP都有一个本地DNS服务器也称为 默认名字服务器</li><li>当一个追发起一个DNS查询时查询到其本地DNS服务器</li><li>起着代理的作用 将查询转发到层次结构中</li></ul><p>迭代查询</p><p>主机 cis.poly.edu 想知道主机 gaia.cs.umass.edu的IP地址</p><p>更服务器返回的不是查询结果而是下个NS的地址</p><p>最后由权威名字服务器给出解析结果</p><p>当前联络的服务器给出可以联系的服务器的名字</p><p>我不知道这个名字 但是可以向则会个服务器请求</p><p>DNS协议 报文</p><p>DNS协议 查询和响应的报文的报文格式相同</p><p>报文首部 标识符 id 16位</p><p>flasgs</p><ul><li>查询 应答</li><li>希望递归</li><li>递归可用</li><li>应答权威</li></ul><p>提高性能 缓存</p><ul><li><p>一旦名字服务器 学到了一个映射就将该映射缓存起来</p></li><li><p>更服务器通常都在本地服务器中缓存着</p><ul><li>使得根服务器 不用经常被访问</li></ul><p>目的 提高效率</p><p>可能存在的问题 如果情况变化 缓存结果和权威资源记录不一致</p><p>解决方法 TTL（默认两天）</p></li></ul><p>新增一个域</p><ul><li>在上级域的名字服务器加两条记录 指向这个域 和域名服务器地址</li><li>在新增子域的名字服务器上运行名字服务器 负责本域名字解析 名字-&gt;IP</li></ul><h3 id="P2P应用"><a href="#P2P应用" class="headerlink" title="P2P应用"></a>P2P应用</h3><p>没有或极少一直运行的服务器</p><p>任意端之间可直接通信</p><p>Peer节点间歇上网 每次IP地址都有可能变化</p><ul><li>文件分发</li><li>流媒体</li><li>VOIP</li></ul><p>C&#x2F;S模式</p><ul><li>服务器传输 都是由服务器发送给peer 服务器必须顺序传输N个文件拷贝</li></ul><p>客户端必须下载一个文件拷贝</p><p>$d_{min}$ &#x3D; 客户端最小的下载速率</p><p>下载代开你最小的客户端下载的时间： F&#x2F;$d_{min}$</p><p>采用C-S方法将一个F大小的文件分发给N个客户端耗时<br>$$<br>D_{C-S}&gt;max{NF&#x2F;U_{s}},F&#x2F;d_{min}<br>$$<br>P2P模式</p><p>服务器传输： 最少需要上载一份拷贝</p><ul><li>发送一个拷贝的时间 F&#x2F;us</li></ul><p>客户端 每个客户端必须下载一个拷贝</p><p>所有客户端总体下载量NF</p><ul><li>最大上载带宽是u + $\sum u$</li><li>除了服务器可以上载 其他所有的peer节点都可以上载</li></ul><p>P2P系统与客户端服务器模式不同的是随着请求数量的增加 提供服务的人也增加 性能高 并且可扩展性好</p><h3 id="CDN"><a href="#CDN" class="headerlink" title="CDN"></a>CDN</h3><p>Content Distribution Networks（内容分发网络）</p><p>流化播放 边下边看（有缓存）减少带宽和等待时间</p><h4 id="多媒体流化服务-DASH"><a href="#多媒体流化服务-DASH" class="headerlink" title="多媒体流化服务 DASH"></a>多媒体流化服务 DASH</h4><p>服务器：</p><ul><li>将视频文件分割成多个块</li><li>每个块独立存储，编码与不同码率</li><li>告示文件： 提供不同的URL</li></ul><p>客户端</p><ul><li>先获取告示文件</li><li>周期性的测量服务器到客户端的带宽</li><li>查询告示文件在一个时刻请求一个块 HTTP指定直接范围<ul><li>如果带宽够请求最大码率</li><li>不同时刻请求不同的编码块</li></ul></li><li>智能客户端 动态的决定请求什么视频块</li></ul><p>通过CDN 全网部署缓存节点，存储服务内容，就近为用户提供服务，提高用户体验  俗称内容加速服务</p><p>enter deep 将CDN服务器深度到接入网</p><ul><li>更接近用户 数量多，离用户近</li><li>Akamai 1700个位置</li></ul><p>bring home 部署在关键位置</p><ul><li>采用租用线路将服务器连接</li></ul><h3 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h3><p>Socket编程</p><h3 id="UDP"><a href="#UDP" class="headerlink" title="UDP"></a>UDP</h3><h2 id="传输层"><a href="#传输层" class="headerlink" title="传输层"></a><strong>传输层</strong></h2><p>传输服务和协议</p><ul><li><p>为用韵在不同主机上的应用进程提供逻辑通信</p></li><li><p>传输协议运行在端系统</p><ul><li>发送方将应用层报文分为报文段，然后传递给网络层</li><li>接收方 将报文段重组成报文 然后传递给应用层</li></ul><p>有多个传输层协议可供应用选择：</p><p>TCP UDP</p></li></ul><p>网络层提供主机间的逻辑通信</p><p>传输层提供进程间的逻辑通信</p><ul><li>依赖网络层的服务器</li><li>对网络层的服务进行增强</li></ul><p>+++</p><h3 id="多路复用和解复用"><a href="#多路复用和解复用" class="headerlink" title="多路复用和解复用"></a>多路复用和解复用</h3><ul><li>解复用作用： TCP或者UDP实体采用那些信息，将报文段数据部分交给正确的socket 从而交给正确的进程</li><li>主机收到IP数据报<ul><li>每个数据报有源IP地址和目标地址</li><li>每个数据报承载一个传输层报文段</li><li>每个报文段有一个源端口号和目标端口号</li></ul></li><li>主机使用IP地址和端口号将报文发送给合适的套接字</li></ul><h3 id="无连接传输UDP"><a href="#无连接传输UDP" class="headerlink" title="无连接传输UDP"></a>无连接传输UDP</h3><p>UDP socket 没有目标IP和端口</p><p>因此每次传输数据的时候需要指定对方IP和端口</p><p>好处是 不用握手 少了建立连接的延时</p><h5 id="UDP校验和"><a href="#UDP校验和" class="headerlink" title="UDP校验和"></a>UDP校验和</h5><p>发送方</p><ul><li>将报文的内容视为16比特的整数</li><li>校验和： 报文段的加法和（1的补运算）</li><li>发送方将校验和放在UDP的校验和字段</li></ul><p>接受方：</p><p>计算收到的报文段的校验和</p><p>检查计算出的校验和与检验的字段内容是否相等</p><ul><li>不相等  检查到差错</li><li>相等 没有检查出差错 但是可能还有差错</li></ul><p>对两个16bit相加后取反码运算 将其加起来（1变0 0变1）如果溢出就回卷（把溢出位加到最后一位）如果分组没有差错结果应该是16个1</p><h3 id="可靠传输的原理"><a href="#可靠传输的原理" class="headerlink" title="可靠传输的原理"></a>可靠传输的原理</h3><p>底层的IP协议是不可靠，而实现在不可靠的基础上实现可靠，就是可靠传输 比如TCP</p><h5 id="不可靠信道的传输"><a href="#不可靠信道的传输" class="headerlink" title="不可靠信道的传输"></a>不可靠信道的传输</h5><p>rdt2.0</p><p>就像打电话一样 对方如果和你说一个事情 你听懂了 你就和他说 好 行（肯定确认） 如果你听不懂对方的话 那你就可以要求其给你重新说一遍（否定确认）</p><p>这就是自动请求重传协议 ARQ</p><p>ARQ需要差错检测 接收方反馈 重传来实现</p><p>但是实际上 肯定确认和否定确认也有可能没有成功传输</p><p>一个解决办法是当手段哦哦含糊不清的 确认时重新传输当前的数据即可，但是这样可能会造成冗余，因此TCP在数据分组上添加了序号 这样就知道数据有没有被重传。</p><p>但是实际上底层的网络层可能也会出现丢包 双方都接受不到对方的消息造成死锁</p><p> 所以引入一个超时重传机制 发送方如果长时间没有收到ACK那么就重传</p><p>需要一个倒计时定时器</p><p>rdt3.0的可靠性很好，但是性能并不好 因为他是一个停等协议 当链路比较长的时候，发送方只有很少的时间在工作，这使得效率十分堪忧 </p><h5 id="流水线协议"><a href="#流水线协议" class="headerlink" title="流水线协议"></a>流水线协议</h5><p>流水线：允许发送方在未得到对方确认的情况下一次发送多个分组</p><ul><li>必须增加序号的范围 用多个bit表示分组的序号</li><li>在发送方接收方要有缓存区</li></ul><p>发送方的缓冲区用于超时重发 接收方的缓冲区是因为发送方发送的速度和接收方提取的速率是不一样的因此需要一个缓存来抵消这种不一致</p><h5 id="滑动窗口协议"><a href="#滑动窗口协议" class="headerlink" title="滑动窗口协议"></a>滑动窗口协议</h5><ul><li>发送缓冲区<ul><li>内存中的一个区域，，落入缓冲区的分组可以发送</li><li>用于存放已发送，但是没有得到确认的分组</li><li>需要重发时可用</li></ul></li><li>发送缓冲区的大小:一次最多可以发送多少个未经确认的分组<ul><li>停止等待协议&#x3D;1</li><li>流水线协议&gt;1，合理的值，不能很大，链路利用率不能够超100%口发送缓冲区中的分组</li><li>未发送的:落入发送缓冲区的分组，可以连续发送出去;</li></ul></li><li>发送缓冲区中的分组<ul><li>未发送的:落入发送缓冲区的分组，可以连续发送出去;</li><li>已经发送出去的、等待对方确认的分组:发送缓冲区的分组只有得到确认才能删除</li></ul></li></ul><p>和滑动窗口一样 只不过这是一个循环队列 每当发送一个右指针向前 当接受到对方返回的ask的时候左指针向前</p><p>GBN </p><ul><li><p>只发送ACK 对顺序接受最高序号的分组</p><ul><li>可能会产生重复的ACK</li></ul></li><li><p>对乱序的分组</p><ul><li>丢弃</li><li>对顺序接受的最高序号进行确认累积</li></ul><p><img src="https://github.com/sizhouLiu/sizhouLiu.github.io/blob/master/2024/05/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E6%96%B9%E6%B3%95/image-20240223002144709.png?raw=true" alt="image-20240223002144709"></p></li></ul><p>选择重传：</p><p><img src="https://github.com/sizhouLiu/sizhouLiu.github.io/blob/master/2024/05/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E6%96%B9%E6%B3%95/image-20240223002244415.png?raw=true" alt="image-20240223002244415"></p><h3 id="面向传输的连接TCP"><a href="#面向传输的连接TCP" class="headerlink" title="面向传输的连接TCP"></a>面向传输的连接TCP</h3><ul><li>点对点:<ul><li>一个发送方，一个接收方</li></ul></li><li>可靠的、按顺序的字节流<ul><li>没有报文边界</li></ul></li><li>管道化(流水线):<ul><li>TCP拥塞控制和流量控制设置窗口大小</li></ul></li><li>全双工数据:<ul><li>在同一连接中数据流双向流动</li><li>MSS最大报文段大小</li></ul></li><li>发送和接收缓存</li><li>面向连接<ul><li>在数据交换之前，通过握手初始化发送方和接收方的状态变量</li></ul></li><li>有流量控制<ul><li>发送方不会淹没接收方·0</li></ul></li></ul><h5 id="TCP报文段结构"><a href="#TCP报文段结构" class="headerlink" title="TCP报文段结构"></a>TCP报文段结构</h5><p><img src="https://github.com/sizhouLiu/sizhouLiu.github.io/blob/master/2024/05/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E6%96%B9%E6%B3%95/image-20240225200014366.png?raw=true" alt="image-20240225200014366"></p><p>序号</p><ul><li>报文段首字节的在字节流的编号（从多少开始发 ）</li></ul><p>确认号</p><ul><li>期望从另一方收到的下一个字节的序号（比如说55意思是55之前的我已经收到了希望你从55及之后开始发）</li><li>累计确认</li></ul><p>往返延迟和超时</p><ul><li>比RTT要长</li></ul><p>SampleRTT 测量报文段发出到收到确认的时间</p><ul><li><p>如果有重传 忽略这次测量</p></li><li><p>SampleRTT会变化 因此估计的RTT应该比较平滑</p><ul><li>对最近的几个测量值求平均 而不是用当前的SampleRTT</li></ul></li></ul><p>$$<br>EstimatedRTT&#x3D;(1-a)<em>EstimatedRTT+a</em>sampleRTT<br>$$</p><ul><li>指数加权移动平均</li><li>过去样本的影响呈指数衰减</li><li>推荐值:a &#x3D;0.125</li></ul><p>因此公式变为<br>$$<br>EstimatedRTT&#x3D;0.875<em>EstimatedRTT + 0.125</em>sampleRTT<br>$$<br>EstimtedRTT+安全边界时间</p><ul><li>EstimatedRTT变化大(方差大)→较大的安全边界时间</li></ul><p>SampleRTT会偏离EstimatedRTT多远:</p><ul><li><p>$$<br>DevRTT &#x3D;(1-β)<em>DevRTT +β</em>|SampleRTT-EstimatedRTT|<br>$$</p></li><li><p>推荐值  &#x3D; $β$ &#x3D; 0.25</p></li></ul><p>超时时间间隔设置为:<br>$$<br>TimeoutInterval&#x3D;EstimatedRTT +4*DevRTT<br>$$<br>可靠数据传输</p><h5 id="快速重传："><a href="#快速重传：" class="headerlink" title="快速重传："></a>快速重传：</h5><p>如果在超时重传定时器溢出之前，接收到连续的三个重复冗余ACK（其实是收到4个同样的ACK，第一个是正常的，后三个才是冗余的），发送端便知晓哪个报文段在传输过程中丢失了，于是重发该报文段，不需要等待超时重传定时器溢出，大大提高了效率。这便是快速重传机制。</p><p>快速重传机制是GBN和SR协议的混合体</p><h5 id="流量控制-1"><a href="#流量控制-1" class="headerlink" title="流量控制"></a>流量控制</h5><p>通信双方各声明一个窗口（缓存大小），标识自己当前能够的处理能力</p><p>接收方控制发送方发，不让发送的太多、太快以至于让接收方的缓冲区溢出</p><p>缓存中的可用的空间<br>$$<br>&#x3D;RcvBuffer-[LastByteRcvd-astByteRead]<br>$$</p><h5 id="TCP连接管理"><a href="#TCP连接管理" class="headerlink" title="TCP连接管理"></a>TCP连接管理</h5><p>在正式交换数据之前，发送方和接收方握手建立通信关系：</p><ul><li>同意建立连接</li><li>同意连接参数</li></ul><p>Q:在网络中，2次握手建立连接总是可行吗?</p><ul><li>变化的延迟(连接请求的段没有丢，但可能超时)</li><li>由于丢失造成的重传(e.9greq_conn(x))</li><li>报文乱序</li><li>相互看不到对方</li></ul><p>导致服务器维护了大量的虚假的半连接 每次建立连接都要开辟一片缓存区域 长此以往使得资源耗尽</p><h6 id="TCP三次握手"><a href="#TCP三次握手" class="headerlink" title="TCP三次握手"></a><em><strong>TCP三次握手</strong></em></h6><h6 id="TCP-三次握手过程是怎样的？"><a href="#TCP-三次握手过程是怎样的？" class="headerlink" title="TCP 三次握手过程是怎样的？"></a>TCP 三次握手过程是怎样的？</h6><p>TCP 是面向连接的协议，所以使用 TCP 前必须先建立连接，而<strong>建立连接是通过三次握手来进行的</strong>。三次握手的过程如下图：</p><p><img src="https://github.com/sizhouLiu/sizhouLiu.github.io/blob/master/2024/05/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E6%96%B9%E6%B3%95/TCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B.drawio.png?raw=true" alt="TCP 三次握手"></p><ul><li>一开始，客户端和服务端都处于 <code>CLOSE</code> 状态。先是服务端主动监听某个端口，处于 <code>LISTEN</code> 状态</li></ul><p><img src="https://github.com/sizhouLiu/sizhouLiu.github.io/blob/master/2024/05/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E6%96%B9%E6%B3%95/format,png-20230309230500953.png?raw=true" alt="第一个报文 —— SYN 报文"></p><ul><li>客户端会随机初始化序号（<code>client_isn</code>），将此序号置于 TCP 首部的「序号」字段中，同时把 <code>SYN</code> 标志位置为 <code>1</code>，表示 <code>SYN</code> 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 <code>SYN-SENT</code> 状态。</li></ul><p><img src="https://github.com/sizhouLiu/sizhouLiu.github.io/blob/master/2024/05/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E6%96%B9%E6%B3%95/format,png-20230309230504118.png?raw=true" alt="第二个报文 —— SYN + ACK 报文"></p><ul><li>服务端收到客户端的 <code>SYN</code> 报文后，首先服务端也随机初始化自己的序号（<code>server_isn</code>），将此序号填入 TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 <code>client_isn + 1</code>, 接着把 <code>SYN</code> 和 <code>ACK</code> 标志位置为 <code>1</code>。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 <code>SYN-RCVD</code> 状态。</li></ul><p><img src="https://github.com/sizhouLiu/sizhouLiu.github.io/blob/master/2024/05/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E6%96%B9%E6%B3%95/format,png-20230309230508297.png?raw=true" alt="第三个报文 —— ACK 报文"></p><ul><li>客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 <code>ACK</code> 标志位置为 <code>1</code> ，其次「确认应答号」字段填入 <code>server_isn + 1</code> ，最后把报文发送给服务端，这次报文可以携带客户到服务端的数据，之后客户端处于 <code>ESTABLISHED</code> 状态。</li><li>服务端收到客户端的应答报文后，也进入 <code>ESTABLISHED</code> 状态。</li></ul><p>从上面的过程可以发现<strong>第三次握手是可以携带数据的，前两次握手是不可以携带数据的</strong>，这也是面试常问的题。</p><p>一旦完成三次握手，双方都处于 <code>ESTABLISHED</code> 状态，此时连接就已建立完成，客户端和服务端就可以相互发送数据了</p><p> TCP 关闭连接</p><ul><li>客户端，服务器分别关闭它自己这一侧的连接·发送FIN bit&#x3D;1的TCP段</li><li>一旦接收到FIN，用ACK回应接到FIN段，ACK可以和它自己发出的FIN段一起发送</li><li>可以处理同时的FIN交换</li></ul><p>双方都可以主动断开连接，断开连接后主机中的「资源」将被释放，四次挥手的过程如下图：</p><p><img src="https://github.com/sizhouLiu/sizhouLiu.github.io/blob/master/2024/05/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E6%96%B9%E6%B3%95/format,png-20230309230614791.png?raw=true" alt="客户端主动关闭连接 —— TCP 四次挥手"></p><ul><li>客户端打算关闭连接，此时会发送一个 TCP 首部 <code>FIN</code> 标志位被置为 <code>1</code> 的报文，也即 <code>FIN</code> 报文，之后客户端进入 <code>FIN_WAIT_1</code> 状态。</li><li>服务端收到该报文后，就向客户端发送 <code>ACK</code> 应答报文，接着服务端进入 <code>CLOSE_WAIT</code> 状态。</li><li>客户端收到服务端的 <code>ACK</code> 应答报文后，之后进入 <code>FIN_WAIT_2</code> 状态。</li><li>等待服务端处理完数据后，也向客户端发送 <code>FIN</code> 报文，之后服务端进入 <code>LAST_ACK</code> 状态。</li><li>客户端收到服务端的 <code>FIN</code> 报文后，回一个 <code>ACK</code> 应答报文，之后进入 <code>TIME_WAIT</code> 状态</li><li>服务端收到了 <code>ACK</code> 应答报文后，就进入了 <code>CLOSE</code> 状态，至此服务端已经完成连接的关闭。</li><li>客户端在经过 <code>2MSL</code> 一段时间后，自动进入 <code>CLOSE</code> 状态，至此客户端也完成连接的关闭。</li></ul><p>你可以看到，每个方向都需要<strong>一个 FIN 和一个 ACK</strong>，因此通常被称为<strong>四次挥手</strong>。</p><p>这里一点需要注意是：<strong>主动关闭连接的，才有 TIME_WAIT 状态。</strong></p><h6 id="为什么挥手需要四次？"><a href="#为什么挥手需要四次？" class="headerlink" title="为什么挥手需要四次？"></a><a href="https://xiaolincoding.com/network/3_tcp/tcp_interview.html#%E4%B8%BA%E4%BB%80%E4%B9%88%E6%8C%A5%E6%89%8B%E9%9C%80%E8%A6%81%E5%9B%9B%E6%AC%A1">为什么挥手需要四次？</a></h6><p>再来回顾下四次挥手双方发 <code>FIN</code> 包的过程，就能理解为什么需要四次了。</p><ul><li>关闭连接时，客户端向服务端发送 <code>FIN</code> 时，仅仅表示客户端不再发送数据了但是还能接收数据。</li><li>服务端收到客户端的 <code>FIN</code> 报文时，先回一个 <code>ACK</code> 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 <code>FIN</code> 报文给客户端来表示同意现在关闭连接。</li></ul><p>从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的 <code>ACK</code> 和 <code>FIN</code> 一般都会分开发送，因此是需要四次挥手。</p><h3 id="拥塞控制原理"><a href="#拥塞控制原理" class="headerlink" title="拥塞控制原理"></a>拥塞控制原理</h3><p>为什么有了流量控制还要有拥塞控制</p><p><strong>在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大….</strong></p><p>所以，TCP 不能忽略网络上发生的事，它被设计成一个无私的协议，当网络发送拥塞时，TCP 会自我牺牲，降低发送的数据量。</p><p>于是，就有了<strong>拥塞控制</strong>，控制的目的就是<strong>避免「发送方」的数据填满整个网络。</strong></p><p>为了在「发送方」调节所要发送数据的量，定义了一个叫做「<strong>拥塞窗口</strong>」的概念。</p><p><strong>拥塞窗口 cwnd</strong>是发送方维护的一个的状态变量，它会根据<strong>网络的拥塞程度动态变化的</strong>。</p><p>我们在前面提到过发送窗口 <code>swnd</code> 和接收窗口 <code>rwnd</code> 是约等于的关系，那么由于加入了拥塞窗口的概念后，此时发送窗口的值是swnd &#x3D; min(cwnd, rwnd)，也就是拥塞窗口和接收窗口中的最小值。</p><p>拥塞窗口 <code>cwnd</code> 变化的规则：</p><ul><li>只要网络中没有出现拥塞，<code>cwnd</code> 就会增大；</li><li>但网络中出现了拥塞，<code>cwnd</code> 就减少；</li></ul><p>只要「发送方」没有在规定时间内接收到 ACK 应答报文，也就是<strong>发生了超时重传，就会认为网络出现了拥塞。</strong></p><p>拥塞控制方法·</p><ul><li>慢启动</li><li>拥塞避免</li><li>拥塞发生</li><li>快速恢复</li></ul><h4 id="慢启动"><a href="#慢启动" class="headerlink" title="慢启动"></a>慢启动</h4><p>TCP 在刚建立连接完成后，首先是有个慢启动的过程，这个慢启动的意思就是一点一点的提高发送数据包的数量</p><p>慢启动的算法 ：<strong>当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1。</strong></p><p>这里假定拥塞窗口 <code>cwnd</code> 和发送窗口 <code>swnd</code> 相等，下面举个栗子：</p><ul><li>连接建立完成后，一开始初始化 <code>cwnd = 1</code>，表示可以传一个 <code>MSS</code> 大小的数据。</li><li>当收到一个 ACK 确认应答后，cwnd 增加 1，于是一次能够发送 2 个</li><li>当收到 2 个的 ACK 确认应答后， cwnd 增加 2，于是就可以比之前多发2 个，所以这一次能够发送 4 个</li><li>当这 4 个的 ACK 确认到来的时候，每个确认 cwnd 增加 1， 4 个确认 cwnd 增加 4，于是就可以比之前多发 4 个，所以这一次能够发送 8 个。</li></ul><p>可以看出慢启动算法，发包的个数是<strong>指数性的增长</strong>。</p><blockquote><p>那慢启动涨到什么时候是个头呢？</p></blockquote><p>有一个叫慢启动门限 <code>ssthresh</code> （slow start threshold）状态变量。</p><ul><li>当 <code>cwnd</code> &lt; <code>ssthresh</code> 时，使用慢启动算法。</li><li>当 <code>cwnd</code> &gt;&#x3D; <code>ssthresh</code> 时，就会使用「拥塞避免算法」。</li></ul><h4 id="拥塞避免算法"><a href="#拥塞避免算法" class="headerlink" title="拥塞避免算法"></a>拥塞避免算法</h4><p>当拥塞窗口 <code>cwnd</code> 「超过」慢启动门限 <code>ssthresh</code> 就会进入拥塞避免算法。</p><p>一般来说 <code>ssthresh</code> 的大小是 <code>65535</code> 字节。</p><p>那么进入拥塞避免算法后，它的规则是：<strong>每当收到一个 ACK 时，cwnd 增加 1&#x2F;cwnd。</strong></p><p>接上前面的慢启动的栗子，现假定 <code>ssthresh</code> 为 <code>8</code>：</p><ul><li>当 8 个 ACK 应答确认到来时，每个确认增加 1&#x2F;8，8 个 ACK 确认 cwnd 一共增加 1，于是这一次能够发送 9 个 <code>MSS</code> 大小的数据，变成了<strong>线性增长。</strong></li><li><img src="https://github.com/sizhouLiu/sizhouLiu.github.io/blob/master/2024/05/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E6%96%B9%E6%B3%95/28.jpg?raw=true" alt="拥塞避免"></li></ul><p>拥塞避免算法就是将原本慢启动算法的指数增长变成了线性增长，还是增长阶段，但是增长速度缓慢了一些。</p><p>就这么一直增长着后，网络就会慢慢进入了拥塞的状况了，于是就会出现丢包现象，这时就需要对丢失的数据包进行重传。</p><p>当触发了重传机制，也就进入了「拥塞发生算法」。</p><h4 id="拥塞发生"><a href="#拥塞发生" class="headerlink" title="拥塞发生"></a>拥塞发生</h4><p>当网络出现拥塞，也就是会发生数据包重传，重传机制主要有两种：</p><ul><li>超时重传</li><li>快速重传</li></ul><p>当发生了「超时重传」，则就会使用拥塞发生算法。</p><p>这个时候，ssthresh 和 cwnd 的值会发生变化：</p><ul><li><code>ssthresh</code> 设为 <code>cwnd/2</code>，</li><li><code>cwnd</code> 重置为 <code>1</code> （是恢复为 cwnd 初始化值，我这里假定 cwnd 初始化值 1）</li></ul><p>接着，就重新开始慢启动，慢启动是会突然减少数据流的。这真是一旦「超时重传」，马上回到解放前。但是这种方式太激进了，反应也很强烈，会造成网络卡顿。</p><p>就好像本来在秋名山高速漂移着，突然来个紧急刹车，轮胎受得了吗。。。</p><blockquote><p>发生快速重传的拥塞发生算法</p></blockquote><p>还有更好的方式，前面我们讲过「快速重传算法」。当接收方发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速地重传，不必等待超时再重传。</p><p>TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，则 <code>ssthresh</code> 和 <code>cwnd</code> 变化如下：</p><ul><li><code>cwnd = cwnd/2</code> ，也就是设置为原来的一半;</li><li><code>ssthresh = cwnd</code>;</li><li>进入快速恢复算法</li></ul><h4 id="快速恢复"><a href="#快速恢复" class="headerlink" title="快速恢复"></a>快速恢复</h4><p>快速重传和快速恢复算法一般同时使用，快速恢复算法是认为，你还能收到 3 个重复 ACK 说明网络也不那么糟糕，所以没有必要像 <code>RTO</code> 超时那么强烈。</p><p>正如前面所说，进入快速恢复之前，<code>cwnd</code> 和 <code>ssthresh</code> 已被更新了：</p><ul><li><code>cwnd = cwnd/2</code> ，也就是设置为原来的一半;</li><li><code>ssthresh = cwnd</code>;</li></ul><p>然后，进入快速恢复算法如下：</p><ul><li>拥塞窗口 <code>cwnd = ssthresh + 3</code> （ 3 的意思是确认有 3 个数据包被收到了）；</li><li>重传丢失的数据包；</li><li>如果再收到重复的 ACK，那么 cwnd 增加 1；</li><li>如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态；</li></ul><h3 id="TCP拥塞"><a href="#TCP拥塞" class="headerlink" title="TCP拥塞"></a>TCP拥塞</h3><h2 id="网络层：数据平面"><a href="#网络层：数据平面" class="headerlink" title="网络层：数据平面"></a><strong>网络层：数据平面</strong></h2><p>网络层的服务</p><ul><li>在发送主机和接收主机对之间传送段(segment)</li><li>在发送端将段封装到数据报中</li><li>在接收端，将段上交给传输层实体</li><li>网络层协议存在于每一个主机和路由器</li><li>路由器检查每一个经过它的IP数据报的头部</li></ul><p>网络层的功能</p><ul><li>转发：将分组从路由器的输入接口转发到合适的输出接口</li><li>路由： 使用路由算法来决定分组从发送主机到目标接受主机的路径</li></ul><p>转发是单个路口的过程</p><p>路由是源目标到目的的路径规划的过程</p><p>其实好像就算是 控制平面是网络层做的事情 数据平面是网络层的功能</p><p>数据平面：</p><ul><li>本地，每个路由器功能</li><li>决定从路由器输入端口到达的分组如何转发到输出端口</li><li>转发功能：<ul><li>传统方式基于目标地址和转发表</li><li>SDN方式 基于多个字段+流表</li></ul></li></ul><p>SDN其实可以理解为有一大堆机器算路由表 然后分发给路由器把控制平面从路由器剥离出来 达到解耦合的目的</p><p>控制平面</p><ul><li><p>网络范围内的逻辑</p></li><li><p>决定数据报如何在路由器之间路由，决定数据报从源到目标主机之间的端到端路径”</p></li><li><p>2个控制平面方法:</p><ul><li><p>传统的路由算法:在路由器中被实现</p></li><li><p>software-definednetworking(SDN):在远程的服务器中实现</p></li></ul></li><li><p>连接建立<br>在某些网络架构中是第三个重要的功能O ATM, frame relay,X.25</p></li><li><p>在分组传输之前，在两个主机之间，在通过一些路由器所构成的路径上建立一个网络层连接</p><ul><li>涉及到路由器</li></ul></li><li><p>网络层和传输层连接服务区别:</p><ul><li>网络层:在2个主机之间，涉及到路径上的一些路由器</li><li>传输层:在2个进程之间，很可能只体现在端系统上(TCP连接)</li></ul></li></ul><p>+++</p><h3 id="路由器组成"><a href="#路由器组成" class="headerlink" title="路由器组成"></a>路由器组成</h3><h3 id="IP-internet-Protocol"><a href="#IP-internet-Protocol" class="headerlink" title="IP internet Protocol"></a>IP internet Protocol</h3><h3 id="通用转发SDN"><a href="#通用转发SDN" class="headerlink" title="通用转发SDN"></a>通用转发SDN</h3><h2 id="网络层：控制平面"><a href="#网络层：控制平面" class="headerlink" title="网络层：控制平面"></a><strong>网络层：控制平面</strong></h2><p>+++</p><h3 id="路由选择算法"><a href="#路由选择算法" class="headerlink" title="路由选择算法"></a>路由选择算法</h3><h3 id="自治系统内部的路由选择"><a href="#自治系统内部的路由选择" class="headerlink" title="自治系统内部的路由选择"></a>自治系统内部的路由选择</h3><h3 id="ISP之间的路由选择-BGP"><a href="#ISP之间的路由选择-BGP" class="headerlink" title="ISP之间的路由选择  BGP"></a>ISP之间的路由选择  BGP</h3><h3 id="SDN控制平面"><a href="#SDN控制平面" class="headerlink" title="SDN控制平面"></a>SDN控制平面</h3><h2 id="数据链路层和局域网"><a href="#数据链路层和局域网" class="headerlink" title="数据链路层和局域网"></a><strong>数据链路层和局域网</strong></h2><p>+++</p><h3 id="差错检测和纠正"><a href="#差错检测和纠正" class="headerlink" title="差错检测和纠正"></a>差错检测和纠正</h3><h3 id="多点访协议"><a href="#多点访协议" class="headerlink" title="多点访协议"></a>多点访协议</h3><h3 id="LANs"><a href="#LANs" class="headerlink" title="LANs"></a>LANs</h3><h2 id="网络安全"><a href="#网络安全" class="headerlink" title="网络安全"></a><strong>网络安全</strong></h2><p>+++</p><h3 id="加密原理"><a href="#加密原理" class="headerlink" title="加密原理"></a>加密原理</h3><h3 id="认证"><a href="#认证" class="headerlink" title="认证"></a>认证</h3><h3 id="报文完整性"><a href="#报文完整性" class="headerlink" title="报文完整性"></a>报文完整性</h3><h3 id="密钥分发和证书"><a href="#密钥分发和证书" class="headerlink" title="密钥分发和证书"></a>密钥分发和证书</h3><h3 id="各个层次的安全性"><a href="#各个层次的安全性" class="headerlink" title="各个层次的安全性"></a>各个层次的安全性</h3><h3 id="防火墙"><a href="#防火墙" class="headerlink" title="防火墙"></a>防火墙</h3><h3 id="攻击和对策"><a href="#攻击和对策" class="headerlink" title="攻击和对策"></a>攻击和对策</h3><h2 id="无线和移动网络"><a href="#无线和移动网络" class="headerlink" title="无线和移动网络"></a><strong>无线和移动网络</strong></h2><p>+++</p><h3 id="软件定义网络"><a href="#软件定义网络" class="headerlink" title="软件定义网络"></a>软件定义网络</h3><h3 id="命名数据网络"><a href="#命名数据网络" class="headerlink" title="命名数据网络"></a>命名数据网络</h3><h2 id="多媒体网络"><a href="#多媒体网络" class="headerlink" title="多媒体网络"></a><strong>多媒体网络</strong></h2><p>TODO：</p><h2 id="网络管理"><a href="#网络管理" class="headerlink" title="网络管理"></a><strong>网络管理</strong></h2>]]></content>
      
      
      
        <tags>
            
            <tag> 计网 </tag>
            
            <tag> http </tag>
            
            <tag> TCP&#92;IP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HTTP2的问题</title>
      <link href="/2024/05/02/HTTP2%E7%9A%84%E9%97%AE%E9%A2%98/"/>
      <url>/2024/05/02/HTTP2%E7%9A%84%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h1 id="HTTP-2"><a href="#HTTP-2" class="headerlink" title="HTTP&#x2F;2"></a>HTTP&#x2F;2</h1><h2 id="HTTP-2-的问题"><a href="#HTTP-2-的问题" class="headerlink" title="HTTP&#x2F;2 的问题"></a><strong>HTTP&#x2F;2 的问题</strong></h2><p><strong>队头阻塞</strong></p><p><strong>HTTP&#x2F;2解决了HTTP的队头阻塞问题，但是并没有解决TCP队头阻塞问题！</strong></p><p>HTTP&#x2F;1.1相比较于HTTP&#x2F;1.0来说，最主要的改进就是引入了持久连接（keep-alive）。</p><p><strong>所谓的持久连接就是：在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟。</strong></p><p>引入了持久连接之后，在性能方面，HTTP协议有了明显的提升。</p><p>HTTP&#x2F;1.1允许在持久连接上使用请求管道，是相对于持久连接的又一性能优化。</p><p>所谓请求管道，就是在HTTP响应到达之前，可以将多条请求放入队列，当第一条HTTP请求通过网络流向服务器时，第二条和第三条请求也可以开始发送了。在高时延网络条件下，这样做可以降低网络的环回时间，提高性能。</p><p><strong>但是，对于管道连接还是有一定的限制和要求的，其中一个比较关键的就是服务端必须按照与请求相同的顺序回送HTTP响应。</strong></p><p>这也就意味着，如果一个响应返回发生了延迟，那么其后续的响应都会被延迟，直到队头的响应送达。这就是所谓的<strong>HTTP队头阻塞</strong>。</p><p>但是HTTP队头阻塞的问题在HTTP&#x2F;2中得到了有效的解决。<strong>HTTP&#x2F;2废弃了管道化的方式</strong>，而是创新性的引入了帧、消息和数据流等概念。<strong>客户端和服务器可以把 HTTP 消息分解为互不依赖的帧，然后乱序发送，最后再在另一端把它们重新组合起来。</strong></p><p><strong>因为没有顺序了，所以就不需要阻塞了，就有效的解决了HTTP对头阻塞的问题。</strong></p><p>但是，HTTP&#x2F;2仍然会存在对头阻塞的问题，那是因为HTTP&#x2F;2其实还是依赖TCP协议实现的。</p><p>TCP传输过程中会把数据拆分为一个个<strong>按照顺序</strong>排列的数据包，这些数据包通过网络传输到了接收端，接收端再<strong>按照顺序</strong>将这些数据包组合成原始数据，这样就完成了数据传输。</p><p>但是如果其中的某一个数据包没有按照顺序到达，接收端会一直保持连接等待数据包返回，这时候就会阻塞后续请求。这就发生了<strong>TCP队头阻塞</strong>。</p><p>HTTP&#x2F;1.1的管道化持久连接也是使得同一个TCP链接可以被多个HTTP使用，但是HTTP&#x2F;1.1中规定一个域名可以有6个TCP连接。而HTTP&#x2F;2中，同一个域名只是用一个TCP连接。</p><p>所以，<strong>在HTTP&#x2F;2中，TCP对头阻塞造成的影响会更大</strong>，因为HTTP&#x2F;2的多路复用技术使得多个请求其实是基于同一个TCP连接的，那如果某一个请求造成了TCP队头阻塞，那么多个请求都会受到影响。</p><h2 id="升级TCP是否可行？"><a href="#升级TCP是否可行？" class="headerlink" title="升级TCP是否可行？"></a><strong>升级TCP是否可行？</strong></h2><p>基于上面我们提到的这些问题，很多人提出来说：既然TCP存在这些问题，并且我们也知道这些问题的存在，甚至解决方案也不难想到，为什么不能对协议本身做一次升级，解决这些问题呢？</p><p>这就涉及到一个”<strong>协议僵化</strong>“的问题。</p><p>我们知道的，想要在家里使用网络有几个前提，首先我们要通过运行商开通网络，并且需要使用路由器，而路由器就是网络传输过程中的一个中间设备。</p><blockquote><p>中间设备是指插入在数据终端和信号转换设备之间，完成调制前或解调后某些附加功能的辅助设备。例如集线器、交换机和无线接入点、路由器、安全解调器、通信服务器等都是中间设备。</p></blockquote><p>在我们看不到的地方，这种中间设备还有很多很多，<strong>一个网络需要经过无数个中间设备的转发才能到达终端用户。</strong></p><p>如果TCP协议需要升级，那么意味着需要这些中间设备都能支持新的特性，我们知道路由器我们可以重新换一个，但是其他的那些中间设备呢？尤其是那些比较大型的设备呢？更换起来的成本是巨大的。</p><p>而且，除了中间设备之外，操作系统也是一个重要的因素，<strong>因为TCP协议需要通过操作系统内核来实现，而操作系统的更新也是非常滞后的。</strong></p><p>所以，这种问题就被称之为”中间设备僵化”，也是导致”协议僵化”的重要原因。这也是限制着TCP协议更新的一个重要原因。</p><p>所以，近些年来，由IETF标准化的许多TCP新特性都因缺乏广泛支持而没有得到广泛的部署或使用！</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h2><p>因为HTTP&#x2F;2底层是采用TCP协议实现的，虽然解决了HTTP队头阻塞的问题，但是对于TCP队头阻塞的问题却无能为力。</p><p>TCP传输过程中会把数据拆分为一个个<strong>按照顺序</strong>排列的数据包，这些数据包通过网络传输到了接收端，接收端再<strong>按照顺序</strong>将这些数据包组合成原始数据，这样就完成了数据传输。</p><p>但是如果其中的某一个数据包没有按照顺序到达，接收端会一直保持连接等待数据包返回，这时候就会阻塞后续请求。这就发生了<strong>TCP队头阻塞</strong>。</p><p>另外，TCP这种可靠传输是靠三次握手实现的，TCP三次握手的过程客户端和服务器之间需要交互三次，那么也就是说需要消耗1.5 RTT。如果是HTTPS那么消耗的RTT就更多。</p><p>而因为很多中间设备比较陈旧，更新换代成本巨大，这就导致TCP协议升级或者采用新的协议基本无法实现。</p><p>所以，HTTP&#x2F;3选择了一种新的技术方案，那就是基于UDP做改造，这种技术叫做QUIC。</p><h1 id="HTTP3"><a href="#HTTP3" class="headerlink" title="HTTP3"></a>HTTP3</h1><h2 id="QUIC协议"><a href="#QUIC协议" class="headerlink" title="QUIC协议"></a><strong>QUIC协议</strong></h2><p>HTTP&#x2F;2之所以”被弃用”，是因为他使用的传输层协议仍然是TCP，所以HTTP&#x2F;3首要解决的问题就是绕开TCP。</p><p>那么如果研发一种新的协议，同样还是会因为受到中间设备僵化的影响，导致无法被大规模应用。所以，研发人员们想到了一种基于UDP实现的方式。</p><p>于是，Google是最先采用这种方式并付诸于实践的，他们在2013年推出了一种叫做QUIC的协议，全称是Quick UDP Internet Connections。</p><p>在设计之初，Google就希望使用这个协议来取代HTTPS&#x2F;HTTP协议，使网页传输速度加快。2015年6月，QUIC的网络草案被正式提交至互联网工程任务组。2018 年 10 月，互联网工程任务组 HTTP 及 QUIC 工作小组正式将基于 QUIC 协议的 HTTP（英语：HTTP over QUIC）重命名为HTTP&#x2F;3。</p><p><strong>所以，我们现在所提到的HTTP&#x2F;3，其实就是HTTP over QUIC，即基于QUIC协议实现的HTTP。</strong></p><p>QUIC协议有以下特点：</p><ul><li>基于UDP的传输层协议：它使用UDP端口号来识别指定机器上的特定服务器。</li><li>可靠性：虽然UDP是不可靠传输协议，但是QUIC在UDP的基础上做了些改造，使得<strong>他提供了和TCP类似的可靠性</strong>。它提供了数据包重传、拥塞控制、调整传输节奏以及其他一些TCP中存在的特性。</li><li>实现了无序、并发字节流：<strong>QUIC的单个数据流可以保证有序交付，但多个数据流之间可能乱序</strong>，这意味着单个数据流的传输是按序的，但是多个数据流中接收方收到的顺序可能与发送方的发送顺序不同！</li><li>快速握手：<strong>QUIC提供0-RTT和1-RTT的连接建立</strong></li><li>使用TLS 1.3传输层安全协议：与更早的TLS版本相比，TLS 1.3有着很多优点，但使用它的最主要原因是其握手所花费的往返次数更低，从而能降低协议的延迟。</li></ul><p>QUIC到底属于TCP&#x2F;IP协议族中的那一层呢？我们知道，QUIC是基于UDP实现的，并且是HTTP&#x2F;3的所依赖的协议，那么，按照TCP&#x2F;IP的分层来讲，他是属于传输层的，也就是和TCP、UDP属于同一层。</p><p>更加细化一点的话，因为QUIC不仅仅承担了传输层协议的职责，还具备了TLS的安全性相关能力，所以，可以通过下图来理解QUIC在HTTP&#x2F;3的实现中所处的位置。</p><h2 id="QUIC的连接建立"><a href="#QUIC的连接建立" class="headerlink" title="QUIC的连接建立"></a><strong>QUIC的连接建立</strong></h2><p>QUIC提出一种新的连接建立机制，基于这种连接接机制，实现了快速握手功能，一次QUIC连接建立可以实现使用 0-RTT 或者 1-RTT 来建立连接。</p><p>UIC在握手过程中使用Diffie-Hellman算法来保证数据交互的安全性并合并了它的加密和握手过程来减小连接建立过程中的往返次数。</p><blockquote><p>Diffie–Hellman (以下简称DH)密钥交换是一个特殊的交换密钥的方法。它是密码学领域内最早付诸实践的密钥交换方法之一。DH可以让双方在完全缺乏对方(私有)信息的前提条件下通过不安全的信道达成一个共享的密钥。此密钥用于对后续信息交换进行对称加密。</p></blockquote><p>QUIC 连接的建立整体流程大致为：QUIC在握手过程中使用Diffie-Hellman算法协商初始密钥，初始密钥依赖于服务器存储的一组配置参数，该参数会周期性的更新。初始密钥协商成功后，服务器会提供一个临时随机数，双方根据这个数再生成会话密钥。客户端和服务器会使用新生的的密钥进行数据加解密。</p><p>以上过程主要分为两个步骤：初始握手（Initial handshake）、最终（与重复）握手（Final (and repeat) handshake），分别介绍下这两个过程。</p><p><strong>初始握手（Initial handshake）</strong></p><p>在连接开始建立时，客户端会向服务端发送一个打招呼信息，（inchoate client hello (CHLO)），因为是初次建立，所以，服务端会返回一个拒绝消息（REJ），表明握手未建立或者密钥已过期。</p><p><img src="https://pic2.zhimg.com/80/v2-61ae95afd407dc8097856542c0c88cfd_720w.webp" alt="img"></p><p>但是，这个拒绝消息中还会包含更多的信息（配置参数），主要有：</p><ul><li>Server Config：一个服务器配置，包括服务器端的Diffie-Hellman算法的长期公钥（long term Diffie-Hellman public value）</li><li>Certificate Chain：用来对服务器进行认证的信任链</li><li>Signature of the Server Config：将Server Config使用信任链的叶子证书的public key加密后的签名</li><li>Source-Address Token：一个经过身份验证的加密块，包含客户端公开可见的IP地址和服务器的时间戳。</li></ul><p>在客户端接收到拒绝消息（REJ）之后，客户端会进行数据解析，签名验证等操作，之后会将必要的配置缓存下来。</p><p>同时，在接收到REJ之后，客户端会为这次连接随机产生一对自己的短期密钥（ephemeral Diffie-Hellman private value） 和 短期公钥（ephemeral Diffie-Hellman public value）。</p><p>之后，客户端会将自己刚刚产生的短期公钥打包一个Complete CHLO的消息包中，发送给服务端。这个请求的目的是将自己的短期密钥传输给服务端，方便做前向保密。</p><p>在发送了Complete CHLO消息给到服务器之后，为了减少RTT，客户端并不会等到服务器的响应，而是立刻会进行数据传输。</p><p>为了保证数据的安全性，客户端会自己的短期密钥和服务器返回的长期公钥进行运算，得到一个初始密钥（initial keys）。</p><p>有了这个初识密钥之后，客户端就可以用这个密钥，将想要传输的信息进行加密，然后把他们安全的传输给服务端了。</p><p>另外一面，接收到Complete CHLO请求的服务器，解析请求之后，就同时拥有了客户端的短期公钥和自己保存的长期密钥。这样通过运算，服务端就能得到一份和客户端一模一样的初始密钥（initial keys）。</p><p>接下来他接收到客户端使用初始密钥加密的数据之后，就可以使用这个初始密钥进行解密了，并且可以将自己的响应再通过这个初始密钥进行加密后返回给客户端。</p><p><strong>所以，从开始建立连接一直到数据传送，只消耗了初始连接连接建立的 1 RTT</strong></p><h2 id="最终（与重复）握手"><a href="#最终（与重复）握手" class="headerlink" title="最终（与重复）握手"></a><strong>最终（与重复）握手</strong></h2><p>那么，之后的数据传输就可以使用初始密钥（initial keys）加密了吗？</p><p>其实并不完全是，因为初始密钥毕竟是基于服务器的长期公钥产生的，而在公钥失效前，几乎多有的连接使用的都是同一把公钥，所以，这其实存在着一定的危险性。</p><p>所以，为了达到前向保密 (Forward Secrecy) 的安全性，客户端和服务端需要使用彼此的短期公钥和自己的短期密钥来进行运算。</p><blockquote><p>在密码学中，前向保密（英语：Forward Secrecy，FS）是密码学中通讯协议的安全属性，指的是长期使用的主密钥泄漏不会导致过去的会话密钥泄漏。</p></blockquote><p>那么现在问题是，客户端的短期密钥已经发送给服务端，而服务端只把自己的长期密钥给了客户端，并没有给到自己的短期密钥。</p><p>所以，服务端在收到Complete CHLO之后，会给到服务器一个server hello(SHLO)消息，这个消息会使用初始密钥（initial keys）进行加密。</p><p><img src="https://pic3.zhimg.com/80/v2-593da9ad871376e1b9c94104ec560172_720w.webp" alt="img"></p><p>这个CHLO消息包中，会包含一个服务端重新生成的短期公钥。</p><p>这样客户端和服务端就都有了对方的短期公钥（ephemeral Diffie-Hellman public value）。</p><p>这样，客户端和服务端都可以基于自己的短期密钥和对方的短期公钥做运算，产生一个仅限于本次连接使用的前向保密密钥 (Forward-Secure Key)，后续的请求发送，都基于这个密钥进行加解密就可以了。</p><p>这样，双方就完成了最终的密钥交换、连接的握手并且建立了QUIC连接。</p><p>当下一次要重新创建连接的时候，客户端会从缓存中取出自己之前缓存下来的服务器的长期公钥，并重新创建一个短期密钥，重新生成一个初始密钥，再使用这个初始密钥对想要传输的数据进行加密，向服务器发送一个Complete CHLO 请求即可。这样就达到了0 RTT的数据传输。</p><p><strong>所以，如果是有缓存的长期公钥，那么数据传输就会直接进行，准备时间是0 RTT</strong></p><p><strong>以上，通过使用Diffie-Hellman算法协商密钥，并且对加密和握手过程进行合并，大大减小连接过程的RTT ，使得基于QUIC的连接建立可以少到1 RTT甚至0 RTT。</strong></p><p><img src="https://pic4.zhimg.com/80/v2-cc893cfb594e784cc21cc82cb7330df3_720w.webp" alt="img"></p><h2 id="多路复用"><a href="#多路复用" class="headerlink" title="多路复用"></a><strong>多路复用</strong></h2><p>基于TCP的协议实现的HTTP有一个最大的问题那就是队头阻塞问题，那么，在这方面，QUIC是如何解决这个问题的呢？</p><p>TCP传输过程中会把数据拆分为一个个按照顺序排列的数据包，这些数据包通过网络传输到了接收端，接收端再按照顺序将这些数据包组合成原始数据，这样就完成了数据传输。</p><p>但是如果其中的某一个数据包没有按照顺序到达，接收端会一直保持连接等待数据包返回，这时候就会阻塞后续请求。这就发生了TCP队头阻塞。</p><p>类似于HTTP&#x2F;2，<strong>QUIC在同一物理连接上可以有多个独立的逻辑数据流，这些数据流并行在同一个连接上传输，且多个数据流之间间的传输没有时序性要求，也不会互相影响。</strong></p><blockquote><p>数据流（Streams）在QUIC中提供了一个轻量级、有序的字节流的抽象化</p></blockquote><p>QUIC的单个数据流可以保证有序交付，但多个数据流之间可能乱序。这意味着单个数据流的传输是按序的，但是多个数据流中接收方收到的顺序可能与发送方的发送顺序不同！</p><p>也就是说同一个连接上面的多个数据流之间没有任何依赖（不要求按照顺序到达），即使某一个数据包没有达到，也只会影响自己这个数据流，并不会影响到到其他的数据流。</p><h2 id="连接迁移你"><a href="#连接迁移你" class="headerlink" title="连接迁移你"></a><strong>连接迁移你</strong></h2><p>对于TCP连接的识别，需要通过服务器和客户端过双方的ip和端口四个参数进行的。在网络切换的场景中，比如手机切换网络，那么自身的ip就会发生变化。</p><p>这就导致之前的TCP连接就会失效，就需要重新建立。这种场景对于移动端设备普及的今天来说，还是比较频繁的。</p><p>所以，在这一点上，QUIC进行了优化。</p><p><strong>QUIC协议使用特有的UUID来标记每一次连接，在网络环境发生变化的时候，只要UUID不变，就能不需要握手，继续传输数据。</strong></p><h2 id="可靠性"><a href="#可靠性" class="headerlink" title="可靠性"></a><strong>可靠性</strong></h2><p>TCP之所以被称之为可靠链接，不仅仅是因为他有三次握手和四次关闭的过程，还因为他做了很多诸如<strong>流量控制、数据重传、拥塞控制</strong>等可靠性保证。这</p><p>也是为什么一直以来都是以TCP作为HTTP实现的重要协议的原因。</p><p>那么，QUIC想要取代TCP，就需要在这方面也做出努力，毕竟UDP自身是不具备这些能力的。</p><p>TCP拥塞控制是TCP避免网络拥塞的算法，是互联网上主要的一个拥塞控制措施。经典的算法实现有很多，诸如TCP Tahoe 和 Reno、TCP Vegas、TCP Hybla、TCP New Reno、TCP Westwood和Westwood+以及TCP BIC 和 CUBIC等等。</p><p>QUIC协议同样实现了<strong>拥塞控制</strong>。不依赖于特定的拥塞控制算法，并且提供了一个可插拔的接口，允许用户实验。默认使用了 TCP 协议的 Cubic 拥塞控制算法。</p><p>关于<strong>流量控制</strong>，QUIC提供了基于stream和connection两种级别的流量控制，既需要对单个 Stream 进行控制，又需要针对所有 Stream 进行总体控制。</p><p>QUIC的连接级流控，用以限制 QUIC 接收端愿意分配给连接的总缓冲区，避免服务器为某个客户端分配任意大的缓存。连接级流控与流级流控的过程基本相同，但转发数据和接收数据的偏移限制是所有流中的总和。</p><h2 id="弊端"><a href="#弊端" class="headerlink" title="弊端"></a><strong>弊端</strong></h2><p>以上，我们介绍了很多QUIC的相比较于TCP的优点，可以说这种协议相比较于TCP确实要优秀一些。</p><p>因为他是基于UDP的，并没有改变UDP协议本身，只是做了一些增强，虽然可以避开中间设备僵化的问题，但是，在推广上面也不是完全没有问题的。</p><p>首先，<strong>很多企业、运营商和组织对53端口（DNS）以外的UDP流量会进行拦截或者限流</strong>，因为这些流量近来常被滥用于攻击。</p><p>特别是一些<strong>现有的UDP协议和实现易受放大攻击（amplification attack）威胁，攻击者可以控制无辜的主机向受害者投放发送大量的流量。</strong></p><p>所以，基于UDP的QUIC协议的传输可能会受到屏蔽。</p><p>另外，因为UDP一直以来定位都是不可靠连接，所以有很多中间设备对于他的支持和优化程度并不高，所以，出现丢包的可能性还是比较高的。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 计网 </tag>
            
            <tag> http </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>7.1~7.2前往保定考试旅途随笔</title>
      <link href="/2024/05/02/7-1-7-2%E5%89%8D%E5%BE%80%E4%BF%9D%E5%AE%9A%E8%80%83%E8%AF%95%E6%97%85%E9%80%94%E9%9A%8F%E7%AC%94/"/>
      <url>/2024/05/02/7-1-7-2%E5%89%8D%E5%BE%80%E4%BF%9D%E5%AE%9A%E8%80%83%E8%AF%95%E6%97%85%E9%80%94%E9%9A%8F%E7%AC%94/</url>
      
        <content type="html"><![CDATA[<h1 id="7-1-7-2前往保定考试旅途随笔"><a href="#7-1-7-2前往保定考试旅途随笔" class="headerlink" title="7.1~7.2前往保定考试旅途随笔"></a>7.1~7.2前往保定考试旅途随笔</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>今年三月份，我报名参加了日语N2考试。由于考生众多，我没有成功选择到山大作为考点。而且实际上我没有花太多时间来学习，大部分时间都在复习之前学过的内容。这次考试我没有太多底气，但我仍然决定去参加。毕竟N2考试的费用是550块钱，不去的话会觉得很心疼，去了也同样如此。因为七月三号还要参加高数考试，匆忙从保定赶回来再去考试简直是一场灾难。然而，在经过一番思想斗争后，我决定还是去保定参加N2考试。</p><h2 id="旅途"><a href="#旅途" class="headerlink" title="旅途"></a>旅途</h2><h4 id="出发前"><a href="#出发前" class="headerlink" title="出发前"></a>出发前</h4><p>我提前购买了下午三点的火车票。七月份正值放假季节，中考和高考也已结束，大部分大学也陆续放假了（为什么太理放假这么晚呢&#x3D; &#x3D;）。因此，火车票并不容易购买。七月一日中午十二点，我吃完了食堂里六块半的经济套餐，然后回到宿舍整理行李。现代基础设施的完善减少了旅途中的很多麻烦，所以我只带了身份证、手机、N2语法书，还有一些路上吃的食品和一瓶水。在宿舍里闲逛了一阵后，我一点半就前往公交车站准备去太原南站。</p><h4 id="公交车上"><a href="#公交车上" class="headerlink" title="公交车上"></a>公交车上</h4><p>公交车上没有以往星期天那种挤得水泄不通的情景了，大学城的学校基本上已经放假，所以公交车相当空旷。这是我第一次坐上如此空旷的902路公交车，车上只有寥寥十几个人，都是学生，看起来和我一样的很多人是前往南站或太原站的。也许还有一些人是去太原的吧。车内的宽敞空间让我感到非常舒适。公交车在一次次的停靠和行驶中，很快我就到达了南站。</p><h4 id="在南站"><a href="#在南站" class="headerlink" title="在南站"></a>在南站</h4><p>我曾在南京游玩，回程时在南站下车。然而，当时已是晚上九点，南站笼罩在漆黑之中，一片朦胧中无法分辨周围景象。疲惫的旅途使我只想尽快返回学校，无暇顾及南站的容貌。这次我有时间来欣赏南站的建筑风格了。南站前面是一个公园，有许多条蜿蜒曲折的小路，有些人为的痕迹，美感并不十分突出，反而有些多余之感。南站前方是一个广场，中国的火车站广场通常都非常宽广，以应对大量的人流。广场的宽阔程度在一定程度上反映了这个地方的客流量。与吞吐大站如北京站相比，南站和太原站的广场并不宽敞，这说明南站和太原站的客流量并不大。我背着背包走进入站口时，看到武警整齐地在广场上巡逻。广场上还设有许多警亭，显然火车站这种人流众多、人员杂乱的地方存在着安全事故的潜在风险。火车站历来都是诈骗和欺诈的热门地，当然现在随着互联网的兴起，即使在陌生地方，人们也可以通过互联网找到信息，减少了人与人之间的交流，从某种程度上遏制了这类案件的发生。在当前个人社交关系日益碎片化的情况下，人与人之间的交流越来越少，也没有很强的人际联系，因此诈骗的机会也减少了。</p><p>我通过安检进入火车站时已经是两点十几分，火车出发还有一个多小时。我闲暇之余开始观察火车站的结构以及各式各样的人们。太原火车站的候车厅有三层，第一层主要用于安检，并不是主要的候车区域，周围设有厕所和供应热水的房间。热水可以泡面，也可作为饮料，可谓旅途中的必需品。而二层则是主要的候车厅。候车厅内的IED屏幕上显示着各个列车的发车时间和检票站台，工作人员在这里维持秩序并提醒旅客检票。而三层则是各式餐厅，为人们提供丰富的饮食选择，满足他们的渴望填饱肚子的需求。这些餐厅提供各种口味的美食，无论是中餐还是西餐，都能满足不同人的口味偏好。人们可以在这里享受美食，放松身心，为接下来的旅程补充能量。餐厅区域的存在让人们在火车站内不必为饥饿而担忧，提供了方便和便利。</p><p>火车站的人流最能真实地反映当下中国的精神风貌，与网络上所呈现的不同。在车站来来往往的人们中，他们的经历最真实且具有代表性。车站里有返乡的大学生，手拎大包小包的毕业生，还有刚结束高考的学生们外出旅游放松心情。还有灰头土脸的中年男女，看起来像是工地上的工人，他们经常成群结队，互相照应，还有穿着衬衫的中年男士，看起来像是出差。他们代表着中国的新生代和老一代，是两个时代的交汇点。新生代年轻人充满朝气和活力，他们拥抱着现代科技和潮流文化，追求个人价值和自由选择。他们对未来充满希望，并努力追寻自己的梦想。而老一代人则承载着历史的沉淀和智慧的积累。他们经历过风雨，见证了国家的发展和变革。这两代人之间的交流和碰撞，代表着中国社会的多样性和变迁。他们相互启迪，互相影响，共同构建着一个更加开放、包容和进步的社会。他们的共同存在展示了中国社会的丰富性和活力，也为国家的未来发展注入了新的动力和希望。在一圈圈闲逛之中，时间到了三点二十分，开往保定的列车开始检票，我随着人流，走向检票口，正式前往去保定的旅程。</p><h4 id="火车上"><a href="#火车上" class="headerlink" title="火车上"></a>火车上</h4><p>虽然我有心理准备，但刚一上火车就被火车上人员的密集程度深深震撼了。有一种我开学坐绿皮慢火车到学校的既视感。我寻找到我的座位，自言自语地念着座位号24号……突然，面前的一位中年男人告诉我，24号在他旁边。我是25号，所以我旁边就是24号。他直直地看着前方，并没有看向我，但我并没有产生什么疑惑。他站起身让我进去坐下，我的对面坐着一位小妹妹，正在专心地看着一本小说。从外表看，她大约十六七岁的样子。把包放到脚下后我开始和那位中年男人攀谈起来。</p><p>我问他：“您是要去哪儿？”他回答说他要去北京的一家按摩店工作。一提到按摩店，我就想到通常会有一个定语——盲人。然后他告诉我，他是一位视障人士，正如我所预料的。回想起来，他的眼神和行为确实符合一个盲人的特征。我好奇地询问他是先天性还是后天性的视力问题，他回答说是后天的。他从小眼睛就不太好，但还能看清楚东西。然而，随着年龄增长，他的视力状况逐渐恶化。他的家人曾带他到各个医院，但现代医学对于他的症状无能为力。到了他三十岁时，他的视力已经恶化到只剩下光感。相比完全失明，他还能感受到光的存在。然而，他的世界一片黑暗，只能辨别一些光线差距较大的物体。但在相对昏暗或没有明暗差异的环境中，他就无法辨别了，所以他经常在楼梯和电线杆等地方碰撞。只有经过多次碰撞后，他才能记住这些物体的位置，所以他在熟悉的地方仍然能够顺利行走。</p><p>他曾经做了很长时间的销售工作，到过很多地方，如大同、河南、河北、天津、川渝地区，可以说是走遍了北方。然而，随着视力恶化，他无法继续从事销售工作。于是，他报名参加了太原的一所特殊教育学校。在学校里，他学习了许多关于人体构造和生理学等知识。接近四十岁的年龄，他在学校已经成为了学生中的长辈，受到了同学们的尊敬。这次也是在暑假的时候去打暑假工，赚一些钱。他早已成家，有一个七岁的女儿。所以这次也是打工赚钱减轻家中负担，毕竟读书可是没有收入来源的。说到他的女儿，他的脸上露出了幸福的神情，和我讲他女儿的事情，说平时虽然压力很大，但是他女儿扑到他身上叫爸爸的时候，他觉得一切压力在那一刻就好像烟消云散了。</p><p>接着他又讲了许多在学校生活的事情。通过他的讲述，我对特殊教育学校有了更多的了解。这是我第一次面对面的听残障人士讲述他们的日常生活。学校的学生都是残障人士，他们也要学习各种课程，试卷使用盲文打印。他们也为考试而担忧。除了身体上的缺陷，他们与普通学生没有太大区别。如果要说有什么不同，那就是他们的内心非常坚强。面对后天的残疾，要克服这种差距感需要很大的勇气。有很多人像史铁生一样变得暴躁和自暴自弃，但他们仍然会在自己的赛道上努力学习，发挥自己的能力，努力生活。</p><p>我们正谈得起劲时，第二站上上来一位中年妇女，坐在我们对面，加入了我们的谈话。她的丈夫在北京的工地上工作，因受了些工伤需要她去照料。他们开始交谈，我也插不上什么话，于是我拿出平板电脑和语法书，临时抱佛脚地复习N2的语法题。在他们谈论的背景声中，火车抵达了下一站——阳泉站。这时，一个年轻人上车坐在我旁边，看见我手上的书，惊讶地说：“你也是去保定考试的吗？”我回答说：“没错。”他将他的包放下，从包里拿出一份N2的真题开始做。在我一次次翻书的过程中，旁边的中年人询问我：“你在看书吗？”我哈哈一声说：“我在临时抱佛脚。”也是因此我们开始聊起现代学生们所面临的压力等话题。在这个过程中，我也开始描述我在学校看到的各种情景，向他们展示我身边的学霸们每天在学校的作息，以及我们每天学习的课程，以及对未来的规划。谈到规划时，我们又谈论起大学教育。我提到大学需要大量的资金来支持各种研究，而山西省的教育由于资金的缺陷发展受到一定的局限性，导致山西的高等教育相对落后。与之相比，南方的一些高校资金充足，能够有更好的发展。我还分享了我去南京游玩时所看到的与山西完全不同的景色，以及我在南京大学门口参观留念的经历。当提到南京大学时，坐在旁边的年轻人突然插话说：“你去的是哪个校区？”我回答说：“鼓楼校区。”他说：“那是我的学校。”我感到非常惊讶，疑惑地问道：“你是放假回家了吗？”他回答说他是今年考上南京大学研究生的，专业是动物学。我望着他，心生羡慕之情，说道：“我也想去南京大学，南京大学的人工智能学科建设得非常好，而且南京的风景优美，气候宜人，是我心中的梦想之地。”他也只是打个哈哈，继续写他的真题，没有多说什么。</p><p>就这样在火车的摇晃中，我们到达了石家庄，距离保定已经不远了。这时我们又开始讨论手机带来的关怀模式，以及如何帮助残障人士使用手机。我们进一步探讨了互联网的现状。我告诉他，现在由于技术框架的成熟，许多功能都可以模块化，以前需要大团队从头开始构建的项目，现在只需要少数几个人就能完成。尤其是人工智能的快速发展，许多公司专注于小而精的领域，例如Midjourney这样的公司，仅有八个人就能打造出市值上亿美元的企业。</p><p>然后，他告诉我他提前通过12306热线申请了残障人士服务，在下车时会有工作人员一直陪同他到地铁站。他还提到，现在国家对残障人士的关怀越来越好，包括他所就读的学校也是免费的。这时我才意识到，其实身边存在许多我们所不了解的细节和关怀。</p><p>在一句句的对话中，时间过得非常快。旁边的年轻小哥突然问我是否已经预订了酒店，我回答说已经提前预订好了。我们一起研究了考试地点和酒店，决定在下车后一起行动。最后阶段，坐在对面的小妹也加入了我们的对话。她在太原的一所学校学习材料学，但不愿透露学校的名字。</p><p>学历、学校、技术栈、实习和论文等。这些事情不仅压在我们身上，同时也疏远了人与人之间的距离。这是一个既好又坏的时代，在市场经济的大背景下，我们拥有极高的自由度，可以选择自己希望从事的职业。不再需要像父辈那样长时间积累经验，被限定在某个框框里。然而，自由也带来了竞争的激烈。好的资源是每个人都渴望得到的，稍有松懈就可能被他人夺走自己的位置。那位小妹选择沉默，应该也不例外是因为这些原因。</p><p>我们到达保定站后，整理好行李，与一路上的中年男性告别，他祝愿我们考试顺利。我笑了笑，也祝他在北京的工作一切顺利。虽然只是短短三个小时的交谈，但说实话，还是有些不舍。但旅途就是这样，相逢又相离。每个人都有自己要去完成的事情，旅途只是暂时将我们聚集在一起，之后我们都要投身于自己的事务中去。</p><h4 id="在保定"><a href="#在保定" class="headerlink" title="在保定"></a>在保定</h4><p>一下火车，我就感受到了保定扑面而来的热浪。我原本以为太原已经很热了，没想到保定更甚。出了保定站，我和小哥一起打车去他的宾馆，而我的宾馆离他并不远。在路上，我们开始讨论晚餐的问题。我提到保定有名的驴肉火烧，我们是否要去找一家店尝一尝。他也表示同意。我向司机师傅询问附近是否有好吃的驴肉火烧店，但司机告诉我们这附近没有什么好的地方，而且由于时间紧迫，我们也无法专门在保定游玩。只好放弃了这个计划，在宾馆附近找了一家卖凉皮的店解决晚餐。吃完饭后互相道别，我朝着我的酒店前进。</p><p>在路上，我观察着保定城区的建设。感觉就像回到了灵丘县一样，一片破旧的景象，建筑风格也相似。这是理所当然的，毕竟灵丘和保定是接壤的地方，而且保定也不是多富裕的地方，相似的风格是不可避免的。</p><p>到达酒店后，我打开空调遮蔽外部的酷热，然后冲了个澡。疲惫的我躺在床上玩了一会手机，向家人报平安后就入睡了。转眼第二天就到了。我在酒店订了外卖的驴肉火烧和馄饨作为午餐。那肥瘦有秩的驴肉火烧，咬下去，外皮酥脆，里面的肉与小麦一起在口中释放出美味。油脂的香气与小麦的香气交织在一起，让味蕾陶醉。吃了两个后仍然回味无穷。</p><p>午饭后，我离开房间前往考场。路上依然炎热难耐，我看到身边也有背着背包的旅客，他们与我同向同行，看来我们有着相同的目的。走了大约半小时，我们到达一个学校门口，许多背着背包的年轻人聚集在这里，显然这就是考场所在地。尽管大家年龄、性别各异，但我们都透露着一股宅气。我身穿一件IEM冠军T恤，有人认出我，向我说理赔难牛逼，我笑了笑。还有人跟我攀谈，表示紧张，我安慰他说没事放松心态，我也只是凭着N2.5的水平去考N2，放宽心。</p><h2 id="考试"><a href="#考试" class="headerlink" title="考试"></a>考试</h2><p>到了考试时间，大门打开，工作人员开始检查准考证和身份证。这所小学也是非常破旧的，我跟着人群找到了我的考场。炎热的天气让大家都汗流浃背，边拿东西扇风边走向考场。由于考场是在小学里，座椅都非常矮小，我作为一米八的个子坐在那里非常拘束和不便。我观察着考场上的每个人，有几个看起来像初高中生的人，也有像我一样的大学生，甚至还有一位大约四十多岁的中年妇女也在考场上。</p><p>教室里有几个电扇，所以考场上的温度并没有太难受（比太理还好一些）。在大喇叭里播放了各种提示和注意事项后，考试开始了。我拿到了一本被定成小册子一样的卷子，我迅速完成了文法和单词部分，然后开始做阅读理解。题目并不是特别难，但我之前没有做过这种类型的题，推进速度很慢。到后面越来越紧张，阅读理解的题目实在太多，而我阅读速度并不快，结果我最终没有完成，有三个选择题是瞎蒙的。</p><p>文法测验结束后是听力测验，休息了十分钟后，在一声声“天気がいいから、散歩しましょう”（因为天气好，我们去散步吧）的提示下，听力测试开始了。由于我的听力不好，基本上也是半蒙半做。考试结束后，我感到如释重负，走出考场去和小哥会和。人数非常多，而且还出现了交通拥堵，我们花了很多时间才打上车前往保定东站。他要去山东，而我急于赶往太原。在东站我们分别，各自奔向自己的旅途。</p><h2 id="归途"><a href="#归途" class="headerlink" title="归途"></a>归途</h2><p>回程的路上并没有什么特别引人注意的事情，非常平淡。只有在站台等车的时候，被红金色车厢的复兴号速度所震撼。在点外卖的时候，我多点了几个火烧，打算带回去分给朋友。为了考试，我在动车上看高数的课程和真题。高铁有空调和插座，比火车舒适许多。不知不觉中，我已经到达了太原。</p><p>在太原南站，我在地下兜兜转转找到了一个网约车停车场。南站的地下布局非常复杂，我打车后，尽管司机离我不远，我仍然不知道应该去哪里找他。只能等司机来接我。司机绕了一个大圈子才找到我，但态度非常和蔼。他询问我是否刚刚接到了订单，我回答说是的。他告诉我他家在榆次，每天七点多就不接单了，而我恰好是他最后一单。在路上，我逐渐熟悉的景色出现了，我回到了学校。司机说谢谢乘车，我也回答着小心路程。回到学校后，我把火烧分给了朋友们，然后立即投入到紧张的复习中。</p><h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>回顾这次前往保定的旅程，我不禁感慨万分。在这短短的两天里，我遇到了许多有趣而特别的人，聆听了他们的故事，分享了彼此的经历和见解。旅途中的火车车厢、公交车、考场和宾馆都成为了我们相聚和别离的见证。每一个细节都彰显着生活的多样性和奇妙之处。</p><p>通过与那位视障人士的交谈，我对特殊教育学校的理解更加深刻，也对身体有缺陷的人们充满了敬意。他们面对挑战，勇敢面对生活，为自己创造机会，证明了坚持和努力的重要性。与那位中年男性的对话让我更加珍惜现在的自由和机会，也让我深刻认识到竞争的激烈和自身的努力不可或缺。</p><p>这次旅程不仅让我体验到了不同城市的风景和氛围，也拓宽了我的眼界，让我更加明白自己的责任和使命。作为新生代的一员，我们要学习和掌握更多的知识，积极面对挑战，不断提升自己的能力和素养。同时，我们也应该尊重和关注他人的需求和感受，为社会的进步和发展贡献自己的力量。</p><p>旅途结束，我回到学校，投入到紧张的复习中。这段经历成为了我人生中的一段美好回忆，激励着我继续努力追求自己的目标。无论是旅途中的相遇还是考试中的挑战，都让我更加坚定了自己的信念和决心。我相信，只要不断努力和奋斗，我们一定能够迎接更加美好的未来。</p><p>愿每一个旅程都成为人生的瑰宝，让我们在不同的路上不断成长，收获智慧和勇气，让我们的人生更加丰富多彩。感谢这次旅程给我带来的一切，我将珍藏这段经历，继续向前迈进。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 生活 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习入门</title>
      <link href="/2024/05/02/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8/"/>
      <url>/2024/05/02/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="深度学习入门"><a href="#深度学习入门" class="headerlink" title="深度学习入门"></a>深度学习入门</h1><h2 id="感知机"><a href="#感知机" class="headerlink" title="感知机"></a>感知机</h2><p>感知机接受两个输入信号。<em>x</em>1、<em>x</em>2是输入信号，<em>y</em>是输出信号，<em>w</em>1、<em>w</em>2是权重（<em>w</em>是weight的首字母）。图中的○称为“神经元”或者“节点”。输入信号被送往神经元时，会被分别乘以固定的权重（<em>w</em>1<em>x</em>1、<em>w</em>2<em>x</em>2）。神经元会计算传送过来的信号的总和，只有当这个总和超过了某个界限值时，才会输出1。这也称为“神经元被激活”。这里将这个界限值称为阈值，用符号<em>θ</em>表示。</p><p><img src="/2024/05/02/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8/MyBlog\source_posts\深度学习入门\image-20231215155935558.png" alt="image-20231215155935558"></p><h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h2><h4 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h4><p>将输入信号总和转换为输出信号的就是激活函数<br>$$<br>a &#x3D; b + w_1 x_1 + w_2x_2<br>$$</p><h5 id><a href="#" class="headerlink" title></a></h5><p>$$<br>y &#x3D; h(a)<br>$$</p><h5 id="sigmoid函数"><a href="#sigmoid函数" class="headerlink" title="sigmoid函数"></a>sigmoid函数</h5><p>$$<br>h(x) &#x3D; \frac{1}{1+exp(-x)}<br>$$<br>神经网络中用sigmoid函数作为激活函数，进行信号的转换，转换后的信号被传送给下一个神经元</p><h5 id="softmax"><a href="#softmax" class="headerlink" title="softmax"></a>softmax</h5><p>分类问题中使用的softmax函数可</p><p>$$<br>y_k &#x3D; \frac{exp(a_k)}{\sum_{i&#x3D;1}^{n}exp(a_i)}<br>$$<br><img src="/2024/05/02/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8/MyBlog\source_posts\深度学习入门\image-20231215161514935.png" alt="image-20231215161514935"></p><h4 id="softmax函数的特征"><a href="#softmax函数的特征" class="headerlink" title="softmax函数的特征"></a>softmax函数的特征</h4><p>softmax函数的输出是0*.<em>0到1</em>.*0之间的实数输出总和为1是softmax函数的一个重要性质。正因为有了这个性质，我们才可以把softmax函数的输出解释为“概率”。</p><h2 id="神经网络的学习"><a href="#神经网络的学习" class="headerlink" title="神经网络的学习"></a>神经网络的学习</h2><h4 id="神经网络的学习步骤"><a href="#神经网络的学习步骤" class="headerlink" title="神经网络的学习步骤"></a>神经网络的学习步骤</h4><p>步骤<strong>1</strong>（<strong>mini-batch</strong>）</p><p>从训练数据中随机选择一部分数据。</p><p>步骤<strong>2</strong>（计算梯度）</p><p>计算损失函数关于各个权重参数的梯度。</p><p>步骤<strong>3</strong>（更新参数）</p><p>将权重参数沿梯度方向进行微小的更新。</p><p>步骤<strong>4</strong>（重复）</p><p>重复步骤1、步骤2、步骤3。</p><p>神经网路的特征就是线虫数据中学习，也就是由数据去决定各个参数的值，在神经网络中各种参数的值会是成千上万的，在这种情况下，由人工去决定机器的参数是不现实的事情。</p><p>手写数字识别是深度学习的一个经典案例，每个人写出来的5都是不同的，那么怎么样才能识别一个字是不是五呢，</p><p>从零开始想出一个可以识别5的算法，不如考虑通过有效利用数据来解决这个问题。一种方案是，先从图像中提取特征量再用机器学习技术学习这些特征量的模式。机器学习的方法中，由机器从收集到的数据中找出规律性。与从零开始</p><p>想出算法相比，这种方法可以更高效地解决问题，也能减轻人的负担</p><h4 id="训练数据和测试数据"><a href="#训练数据和测试数据" class="headerlink" title="训练数据和测试数据"></a>训练数据和测试数据</h4><p>我们通过训练数据进行学习，寻找最优的参数；然后，使用测试数据评价训练得到的模型的实际能力。为了正确评价模型的泛化能力，就必须划分训练数据和测试数据。另外，训练数据也可以称为监督数据泛化能力是指处理未被观察过的数据（不包含在训练数据中的数据）的能力。获得泛化能力是机器学习的最终目标。只对某个数据集过度拟合的状态称为过拟合（over fitting）。避免过拟合也是机器学习的一个重要课题</p><h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><p>神经网络以某个指标为线索寻找最优权重参数。神经网络的学习中所用的指标称为损失函数（loss function）。这个损失函数可以使用任意函数，但一般用均方误差和交叉熵误差等。</p><h5 id="均方误差"><a href="#均方误差" class="headerlink" title="均方误差"></a>均方误差</h5><p>$$<br>E &#x3D; \frac{1}{2} \sum_{k}^{}(yk-tk)^2<br>$$</p><p>$$<br>yk是表示神经网络的输出，tk表示监督数据，k表示数据的维数<br>$$</p><h5 id="交叉熵误差"><a href="#交叉熵误差" class="headerlink" title="交叉熵误差"></a>交叉熵误差</h5><p>交叉熵误差（cross entropy error）也经常被用作损失函数。交叉熵误差如下式所示。</p><p>交叉熵是用来评估当前训练得到的<strong>概率分布</strong>与真实分布的差异情况。 它刻画的是实际输出（概率）与期望输出（概率）的距离，也就是交叉熵的值越小，两个概率分布就越接近。<br>$$<br>E &#x3D;  -\sum_{k}^{}t_k\log_{}{y_k}<br>$$</p><h3 id="mini-batch学习"><a href="#mini-batch学习" class="headerlink" title="mini-batch学习"></a>mini-batch学习</h3><p>$$<br>E &#x3D; -\frac{1}{N}\sum_{n}^{} \sum_{k}^{}t_{nk}\log_{}{y_{nk}}<br>$$</p><p>假设数据有<em>N</em>个，N表示第<em>n</em>个数据的第<em>k</em>个元素的值（$ $是神经网络的输出，tnk是监督数据）</p><h3 id="偏导数"><a href="#偏导数" class="headerlink" title="偏导数"></a>偏导数</h3><p>$$<br>f(x_0,x_1) &#x3D; x_0^2+x_1^2<br>$$</p><p>这个函数有两个参数式（4*.<em>6）有两个变量，所以有必要区分对哪个变量求导数，即对</em>x<em>0和</em>x*1两个变量中的哪一个求导数。另外，我们把这里讨论的有多个变量的函数的导数称为偏导数。用数学式表示的话，可以写成 $\frac{\partial f}{\partial x_0} $、$\frac{\partial y}{\partial x_1} $</p><h3 id="梯度"><a href="#梯度" class="headerlink" title="梯度"></a>梯度</h3><p>像 $\frac{\partial f}{\partial x_0} $、$\frac{\partial y}{\partial x_1} $​这样的由全部变量的偏导数汇总而成的向量称为梯度（gradient）。梯度指示的方向是各点处的函数值减小最多的方向 。</p><h3 id="梯度法"><a href="#梯度法" class="headerlink" title="梯度法"></a>梯度法</h3><p>深度学习需要找到最优参数（权重与偏置），但是损失函数通常非常的繁杂，无法通过人工计算的方式来做优化，于是我们使用梯度下降的方式来减少损失函数</p><p>但是梯度下降的方式可能不会达到一个全局最优解 而是陷入一个局部的最优解。虽然梯度的方向并不一定指向最小值，但沿着它的方向能够最大限度地减小函数的值。</p><p>此时梯度法就派上用场了。在梯度法中，函数的取值从当前位置沿着梯度方向前进一定距离，然后在新的地方重新求梯度，再沿着新梯度方向前进，如此反复，不断地沿梯度方向前进。像这样，通过不断地沿梯度方向前进，逐渐减小函数值的过程就是梯度法（gradient method）。梯度法是解决机器学习中最优化问题的常用方法，特别是在神经网络的学习中经常被使用。<br>$$<br>x_0 &#x3D;x_0-\eta\frac{\partial f}{\partial x_1}<br>$$</p><p>$$<br>x_1 &#x3D;x_1-\eta\frac{\partial f}{\partial x_1}<br>$$</p><p><em>η</em>表示更新量，在神经网络的学习中，称为学习率（learning rate）。学习率决定在一次学习中，应该学习多少，以及在多大程度上更新参数。</p><h3 id="随机梯度下降法（stochastic-gradient-descent）"><a href="#随机梯度下降法（stochastic-gradient-descent）" class="headerlink" title="随机梯度下降法（stochastic gradient descent）"></a>随机梯度下降法（stochastic gradient descent）</h3><p>“随机”指的是“随机选择的”的意思，因此，随机梯度下降法是“对随机选择的数据进行的梯度下降法</p><h2 id="误差反向传播法"><a href="#误差反向传播法" class="headerlink" title="误差反向传播法"></a>误差反向传播法</h2><h3 id="链式法则"><a href="#链式法则" class="headerlink" title="链式法则"></a>链式法则</h3><p>如果某个函数由复合函数表示，则该复合函数的导数可以用构成复合函数的各个函数的导数的乘积表示(其实就是从里向外一层一层算)</p><h4 id="反向传播法"><a href="#反向传播法" class="headerlink" title="反向传播法"></a>反向传播法</h4><p>相反与正向传播 反向传播是乘以对应节点的导数</p><p>以$z &#x3D; x + y$为例其导数分别为<br>$$<br>\frac{\partial z}{\partial x}&#x3D;1<br>$$</p><p>$$<br>\frac{\partial z}{\partial y}&#x3D;1<br>$$</p><p>因此加法节点的反向传播只是将输入信号输出到下一个节点</p><h5 id="乘法节点的反向传播"><a href="#乘法节点的反向传播" class="headerlink" title="乘法节点的反向传播"></a>乘法节点的反向传播</h5><p>以$z&#x3D;xy$为例<br>$$<br>\frac{\partial z}{\partial x}&#x3D;y<br>$$</p><p>$$<br>\frac{\partial z}{\partial y}&#x3D;x<br>$$</p><p>乘法的反向传播会将上游的值乘以正向传播时的输入信号的“翻转值”后传递给下游。</p><h2 id="-1"><a href="#-1" class="headerlink" title></a></h2><p>确认数值微分求出的梯度结果和误差反向传播法求出的结果是否一致（严格地讲，是非常相近）的操作称为梯度确认（gradient check）</p><h2 id="与学习相关的技巧"><a href="#与学习相关的技巧" class="headerlink" title="与学习相关的技巧"></a>与学习相关的技巧</h2><h4 id="参数的更新"><a href="#参数的更新" class="headerlink" title="参数的更新"></a>参数的更新</h4><p>神经网络的学习的目的是找到使损失函数的值尽可能小的参数。这是寻找最优参数的问题，解决这个问题的过程称为最优化（optimization）。</p><h4 id="SGD"><a href="#SGD" class="headerlink" title="SGD"></a>SGD</h4><h4 id="Momentum"><a href="#Momentum" class="headerlink" title="Momentum"></a>Momentum</h4><p>和前面的SGD一样，<strong>W</strong>表示要更新的权重参数， 表示损失函数关于<strong>W</strong>的梯度，<em>η</em>表示学习率。这里新出现了一个变量<strong>v</strong>，对应物理上的速度。</p><h4 id="AdaGrad"><a href="#AdaGrad" class="headerlink" title="AdaGrad"></a>AdaGrad</h4><p>学习率作为一种超参数十分重要在关于学习率的有效技巧中，有一种被称为学习率衰减（learning rate decay）的方法，即随着学习的进行，使学习率逐渐减小。</p><p>AdaGrad会为参数的每个元素适当地调整学习率，</p><p>AdaGrad会记录过去所有梯度的平方和。因此，学习越深入，更新的幅度就越小。</p><h4 id="权重的初始值"><a href="#权重的初始值" class="headerlink" title="权重的初始值"></a>权重的初始值</h4><p>在神经网络的学习中，权重的初始值特别重要。设定什么样的权重初始值，经常关系到神经网络的学习能否成功。</p><p>如果想减小权重的值，一开始就将初始值设为较小的值才是正途</p><p>数据分布造成反向传播中梯度的值不断变小，最后消失。这个问题称为梯度消失（gradient vanishing）</p><p>Xavier初始值</p><p>如果前一层的节点数为<em>n</em>，则初始值使用标准差为 $\frac{1}{\sqrt{n}}$的分布</p><h5 id="ReLU的权重初始值"><a href="#ReLU的权重初始值" class="headerlink" title="ReLU的权重初始值"></a>ReLU的权重初始值</h5><p>Xavier初始值是以激活函数是线性函数为前提而推导出来的。因为sigmoid函数和tanh函数左右对称，且中央附近可以视作线性函数，所以适合使用Xavier初始值。但当激活函数使用ReLU时，一般推荐使用ReLU专用的初始值，也就是Kaiming He等人推荐的初始值，也称为“He初始值。</p><p>当前一层的节点数为<em>n</em>时，He初始值使用标准差为 $\sqrt\frac{2}{n}$的高斯分布。当Xavier初始值是$\sqrt\frac{1}{n}$时，（直观上）可以解释为，因为ReLU的负值区域的值为0，为了使它更有广度，所以需要2倍的系数</p><h4 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h4><p>机器学习的问题中，过拟合是一个很常见的问题。</p><p>发生过拟合的原因，主要有以下两个。</p><p>• 模型拥有大量参数、表现力强。</p><p>• 训练数据少</p><h4 id="权值衰减"><a href="#权值衰减" class="headerlink" title="权值衰减"></a>权值衰减</h4><p>权值衰减是一直以来经常被使用的一种抑制过拟合的方法。该方法通过在学习的过程中对大的权重进行惩罚，来抑制过拟合。</p><h4 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h4><p>如果网络的模型变得很复杂，只用权值衰减就难以应对了。在这种情况下，我们经常会使用Dropout方法</p><p>Dropout是一种在学习的过程中随机删除神经元的方法。训练时，随机选出隐藏层的神经元，然后将其删除。被删除的神经元不再进行信号的传递，测试时，虽然会传递所有的神经元信号，但是对于各个神经元的输出，要乘上训练时的删除比例后再输出</p><h4 id="超参数的验证"><a href="#超参数的验证" class="headerlink" title="超参数的验证"></a>超参数的验证</h4><p>超参数是指，比如各层的神经元数量、batch大小、参数更新时的学习率或权值衰减等。如果这些超参数没有设置合适的值，模型的性能就会很差。</p><h5 id="验证数据"><a href="#验证数据" class="headerlink" title="验证数据"></a>验证数据</h5><p>之前使用的数据集分成了训练数据和测试数据，训练数据用于学习，测试数据用于评估泛化能力。由此，就可以评估是否只过度拟合了训练数据(是否发生了过拟合），以及泛化能力如何等。</p><p>如果使用测试数据调整超参数，超参数的值会对测试数据发生过拟合。</p><p>所以调整超参数时，必须使用超参数专用的确认数据。用于调整超参数的数据，一般称为验证数据（validation data）。我</p><h4 id="超参数的最优化"><a href="#超参数的最优化" class="headerlink" title="超参数的最优化"></a>超参数的最优化</h4><p>进行超参数的最优化时，逐渐缩小超参数的“好值”指一开始先大致设定一个范围，从这个范围中随机选出一个超参数（采样），用这个采样到的值进行识别精度的评估；然后，多次重复该操作，观察识别精度的结果，根据这个结果缩小超参数的“好值”的范围。通过重复这一操作，就可以逐渐确定超参数的合适范围。</p><h6 id="最优化的步骤："><a href="#最优化的步骤：" class="headerlink" title="最优化的步骤："></a>最优化的步骤：</h6><ol><li>设定超参数的范围。</li><li>从设定的超参数范围中随机采样。</li><li>使用步骤1中采样到的超参数的值进行学习，通过验证数据评估识别精度（但是要将epoch设置得很小）。</li><li>重复步骤1和步骤2（100次等），根据它们的识别精度的结果，缩小超参数的范围。</li></ol><h2 id="卷积神经网络（Convolutional-Neural-Network，CNN）"><a href="#卷积神经网络（Convolutional-Neural-Network，CNN）" class="headerlink" title="卷积神经网络（Convolutional Neural Network，CNN）"></a>卷积神经网络（Convolutional Neural Network，<strong>CNN</strong>）</h2><h3 id="整体结构"><a href="#整体结构" class="headerlink" title="整体结构"></a>整体结构</h3><h4 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h4><h5 id="全连接层存在的问题"><a href="#全连接层存在的问题" class="headerlink" title="全连接层存在的问题"></a>全连接层存在的问题</h5><p>相邻层的所有神经元之间都有连接，这称为全连接（fully-connected）。</p><p>全连接层存在数据的形状被忽视的问题</p><p>比如，输入数据是图像时，图像通常是高、长、通道方向上的3维形状。但是，向全连接层输入时，需要将3维数据拉平为1维数据。</p><p>图像是3维形状，这个形状中应该含有重要的空间信息。比如，空间上邻近的像素为相似的值、RBG的各个通道之间分别有密切的关联性、相距较远的像素之间没有什么关联等，</p><p>而卷积层可以保持形状不变。当输入数据是图像时，卷积层会以3维数据的形式接收输入数据，并同样以3维数据的形式输出至下一层。因此，在CNN中，可以（有可能）正确理解图像等具有形状的数据</p><p>CNN 中，有时将卷积层的输入输出数据称为<strong>特征图（feature map）</strong>。其中，卷积层的输入数据称为<strong>输入特征图（input feature map）</strong>，输出数据称为<strong>输出特征图（output feature map）</strong>。</p><h5 id="卷积运算"><a href="#卷积运算" class="headerlink" title="卷积运算"></a>卷积运算</h5><p>对于输入数据，卷积运算以一定间隔滑动滤波器的窗口并应用。这里所说的窗口是指图7-4中灰色的3 <em>×</em> 3的部分。如图7-4所示，将各个位置上卷积核的元素和输入的对应元素相乘，然后再求和（有时将这个计算称为乘积累加运算）。</p><h5 id="填充"><a href="#填充" class="headerlink" title="填充"></a>填充</h5><p>在进行卷积层的处理之前，有时要向输入数据的周围填入固定的数据（比如0等），这称为填充（padding）</p><p><img src="/2024/05/02/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8/MyBlog\source_posts\深度学习入门\image-20231227170322471.png" alt="image-20231227170322471"></p><p>卷积运算的填充处理：向输入数据的周围填入<strong>0</strong>（图中用虚线表示填充，并省略了填充的内容“<strong>0</strong>”）</p><h5 id="步幅"><a href="#步幅" class="headerlink" title="步幅"></a>步幅</h5><p>应用滤波器的位置间隔称为步幅（stride）。</p><p><img src="/2024/05/02/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8/MyBlog\source_posts\深度学习入门\image-20231227170408400.png" alt="image-20231227170408400"></p><p>这里，假设输入大小为(<em>H, W</em>)，滤波器大小为(<em>FH, FW</em>)，输出大小为(<em>OH, OW</em>)，填充为<em>P</em>，步幅为<em>S</em>。此时，输出大小可通过式进行计算。<br>$$<br>OH &#x3D; \frac{H+2P-FH}{S}+1<br>$$</p><p>$$<br>OW &#x3D; \frac{W+2P-FW}{S}+1<br>$$</p><p>其实就是拿这个公式算长和宽</p><h4 id="3维数据的卷积运算"><a href="#3维数据的卷积运算" class="headerlink" title="3维数据的卷积运算"></a>3维数据的卷积运算</h4><p>通道方向上有多个特征图时，会按通道</p><p>进行输入数据和滤波器的卷积运算，并将结果相加，从而得到输出。</p><p>在3维数据的卷积运算中，输入数据和滤波器的通道要设为相同的值。</p><p>有多高的数据就要有多少个卷积核</p><h3 id="批处理"><a href="#批处理" class="headerlink" title="批处理"></a>批处理</h3><p>我们希望卷积运算也同样对应批处理。为此，需要将在各层间传递的数</p><p>据保存为4维数据。具体地讲，就是按(batch_num*,* channel*,* height*,* width)</p><p>的顺序保存数据。</p><h4 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h4><p>池化是缩小高、长方向上的空间的运算。</p><p><img src="/2024/05/02/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8/MyBlog\source_posts\深度学习入门\image-20231227214606929.png" alt="image-20231227214606929"></p><p>就是从多的数据变成少的数据</p><p>除了Max池化之外，还有Average池化等，Average池化则是计算目标区域的平均值，在图像识别领域，主要使用Max池化。</p><h5 id="池化层的特征"><a href="#池化层的特征" class="headerlink" title="池化层的特征"></a><strong>池化层的特征</strong></h5><p>没有要学习的参数池化层和卷积层不同，没有要学习的参数。池化只是从目标区域中取最大值（或者平均值），所以不存在要学习的参数。</p><p>通道数不发生变化</p><p>经过池化运算，输入数据和输出数据的通道数不会发生变化。</p><p>计算是按通道独立进行的对微小的位置变化具有鲁棒性（健壮）</p><p>输入数据发生微小偏差时，池化仍会返回相同的结果。因此，池化对输入数据的微小偏差具有鲁棒性。比如，3 <em>×</em> 3的池化的情况下，如图池化会吸收输入数据的偏差（根据数据的不同，结果有可能不一致）</p><ul><li>CNN在此前的全连接层的网络中新增了卷积层和池化层。</li><li>使用im2col函数可以简单、高效地实现卷积层和池化层。</li></ul><h1 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h1><p>深度学习是加深了层的深度神经网络。</p><h2 id="Data-Augmentation"><a href="#Data-Augmentation" class="headerlink" title="Data Augmentation"></a>Data Augmentation</h2><p>Data Augmentation是基于算法“人为地”扩充输入图像（训练图像），比如说对于输入图像，通过施加旋转、垂直或水平方向上的移动等微小变化，增加图像的数量。这在数据集的图像数量有限时尤其有效。Data Augmentation还可以通过其他各种方法扩充图像，比如裁剪图像的“crop处理”、将图像左右翻转的“flip处理”A 等。对于一般的图像，施加亮度等外观上的变化、放大缩小等尺度上的变化也是有效的。不管怎样，通过Data Augmentation巧妙地增加训练图像，就可以提高深度学习的识别精度。虽然这个看上去只是一个简单的技巧，不过经常会有很好的效果。</p><h2 id="加深层的好处"><a href="#加深层的好处" class="headerlink" title="加深层的好处"></a>加深层的好处</h2><p>可以减少网络的参数数量。加深了层的网络可以用更少的参数达到同等水平（或者更强）的表现力。一次5 <em>×</em> 5的卷积运算的区域可以由两次3 <em>×</em> 3的卷积运算抵充。并且，相对于前者的参数数量25（5 <em>×</em> 5），后者一共是18（2 <em>×</em> 3 <em>×</em> 3）</p><p>叠加小型滤波器来加深网络的好处是可以减少参数的数量，扩大感受野（receptive field，给神经元施加变化的某个局部空间区域）。并且，通过叠加层，将 ReLU等激活函数夹在卷积层的中间，进一步提高了网络的表现力。这是因为向网络添加了基于激活函数的“非线性”表现力，通过非线性函数的叠加，可以表现更加复杂的东西。</p><p>加深层的另一个好处就是使学习更加高效。与没有加深层的网络相比，通过加深层，可以减少学习数据，从而高效地进行学习。</p><p>实践中经常会灵活应用使用ImageNet这个巨大的数据集学习到的权重数据，这称为迁移学习，将学习完的权重（的一部分）复制到其他神经网络，进行再学习（fine tuning）。比如，准备一个和 VGG相同结构的网络，把学习完的权重作为初始值，以新数据集为对象，进行再学习。迁移学习在手头数据集较少时非常有效。</p><h3 id="基于GPU的高速化"><a href="#基于GPU的高速化" class="headerlink" title="基于GPU的高速化"></a>基于GPU的高速化</h3><p><strong>GPU</strong>计算的目标就是将这种压倒性的计算能力用于各种用途。所谓GPU计算，是指基于GPU进行通用的数值计算的操作。</p><p>深度学习中需要进行大量的乘积累加运算（或者大型矩阵的乘积运算）。这种大量的并行运算正是GPU所擅长的（反过来说，CPU比较擅长连续的、复杂的计算）。因此，与使用单个CPU相比，使用GPU进行深度学习的运算可以达到惊人的高速化。深度学习的框架中使用了NVIDIA提供的CUDA这个面向GPU计算的综合开发环境。</p><h3 id="分布式学习"><a href="#分布式学习" class="headerlink" title="分布式学习"></a>分布式学习</h3><p>虽然通过GPU可以实现深度学习运算的高速化，但即便如此，当网络较深时，学习还是需要几天到几周的时间。将深度学习的学习过程扩展开来的想法（也就是分布式学习）就变得重要起来。为了进一步提高深度学习所需的计算的速度，可以考虑在多个GPU或者多台机器上进行分布式计算。现在的深度学习框架中，出现了好几个支持多GPU或者多机器的分布式学习的框架。其中，Google的TensorFlow、微软的CNTK（Computational Network Toolki）在开发过程中高度重视分布式学习。以大型数据中心的低延迟·高吞吐网络作为支撑，基于这些框架的分布式学习呈现出惊人的效果</p><p>在使用CNN进行物体检测的方法中，有一个叫作R-CNN的有名的方法。</p><p><img src="/2024/05/02/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8/MyBlog\source_posts\深度学习入门\image-20231227223441101.png" alt="image-20231227223441101"></p><h2 id="Deep-Q-Network（强化学习）"><a href="#Deep-Q-Network（强化学习）" class="headerlink" title="Deep Q-Network（强化学习）"></a>Deep Q-Network（强化学习）</h2><p>让计算机也在摸索试验的过程中自主学习，这称为强化学习（reinforcement learning）,通过计算机与环境的交互不断调整参数.在使用了深度学习的强化学习方法中，有一个叫作Deep Q-Network通称<strong>DQN</strong>。该方法基于被称为Q学习的强化学习算法。</p><p>在Q学习中，为了确定最合适的行动，需要确定一个被称为最优行动价值函数的函数。</p><p>不需要提供游戏的状态只需要输入图像就能够让计算机学习。这是强化学习的最大特点</p>]]></content>
      
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
